{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image \nfrom PIL import ImageFilter\nimport matplotlib.pyplot as plt \nimport time\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-20T17:48:57.788591Z","iopub.execute_input":"2023-06-20T17:48:57.788985Z","iopub.status.idle":"2023-06-20T17:49:05.652794Z","shell.execute_reply.started":"2023-06-20T17:48:57.788955Z","shell.execute_reply":"2023-06-20T17:49:05.651868Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# train\ntrainImages = []\ntrainLabels = []\n\nreadFile = open(\"/kaggle/input/unibuc-dhc-2023/train.csv\",'r')\npair = readFile.readline() #trecem peste prima linie\npair = readFile.readline()\nwhile pair:\n    pair = pair.split(\",\")\n    image = Image.open(\"/kaggle/input/unibuc-dhc-2023/train_images/\" + pair[0])\n    imageArray = np.asarray(image) \n    image.close()\n    trainImages.append(imageArray) # adaug imaginea in vectorul corespunzator\n    trainLabels.append(int(pair[1])) # adaug labelul pozei in vectorul corespunzator\n    pair = readFile.readline()\n        \n        \n# validation\nvalidationImages = []\nvalidationLabels = []\n\nreadFile = open(\"/kaggle/input/unibuc-dhc-2023/val.csv\",'r')\npair = readFile.readline() #trecem peste prima linie\npair = readFile.readline()\nwhile pair:\n    pair = pair.split(\",\")\n    image = Image.open(\"/kaggle/input/unibuc-dhc-2023/val_images/\" + pair[0])\n    imageArray = np.asarray(image) \n    image.close()\n    validationImages.append(imageArray) # adaug imaginea in vectorul corespunzator\n    validationLabels.append(int(pair[1])) # adaug labelul pozei in vectorul corespunzator\n    pair = readFile.readline()\n        \n\n        \n# test\n\n\ntestImages = []\ntestImageNames = []\n        \nreadFile = open(\"/kaggle/input/unibuc-dhc-2023/test.csv\",'r')\npair = readFile.readline() #trecem peste prima linie\npair = readFile.readline()\nwhile pair:\n    pair = pair.rstrip(\"\\n\")\n    image = Image.open(\"/kaggle/input/unibuc-dhc-2023/test_images/\" + pair)\n    imageArray = np.asarray(image) \n    image.close()\n    testImageNames.append(pair)\n    testImages.append(imageArray) \n    pair = readFile.readline()\n    \n\n# arr = np.array(trainImages)\n# print(arr.shape)\n# print(\"test\")\n\n        \n        \ntrainImages = np.stack(trainImages, axis=0)\nvalidationImages = np.stack(validationImages, axis=0)\ntrainLabels = np.stack(trainLabels, axis=0)\nvalidationLabels = np.stack(validationLabels, axis=0)\n\ntrainImages = trainImages/255\nvalidationImages = validationImages/255\n        \n        \ntestImages = np.stack(testImages, axis=0)\ntestImages = testImages/255\n\nmegaTrain = np.concatenate((trainImages, validationImages),axis=0)\nmegaTrainLabels = np.concatenate((trainLabels, validationLabels),axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T17:49:10.243500Z","iopub.execute_input":"2023-06-20T17:49:10.244196Z","iopub.status.idle":"2023-06-20T17:50:35.281234Z","shell.execute_reply.started":"2023-06-20T17:49:10.244162Z","shell.execute_reply":"2023-06-20T17:50:35.280170Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n# classes = np.zeros(96,dtype=int)\n# for i in trainLabels:\n#     classes[i] += 1\n   \n# plt.figure(figsize=(10,6))\n# plt.hist(trainLabels, bins=96, color=\"purple\",ec=\"black\")\n# plt.plot\n\n# print(classes)\nprint(testImages.shape) ","metadata":{"execution":{"iopub.status.busy":"2023-06-20T18:16:37.329517Z","iopub.execute_input":"2023-06-20T18:16:37.329917Z","iopub.status.idle":"2023-06-20T18:16:37.335700Z","shell.execute_reply.started":"2023-06-20T18:16:37.329885Z","shell.execute_reply":"2023-06-20T18:16:37.334747Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"(5000, 64, 64, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"def validate(model, validationImages, validationLabels):\n    \n    # Convert validation labels to numpy array\n    validationLabels = np.array(validationLabels)\n    \n    # Evaluate the model\n    loss, accuracy = model.evaluate(validationImages, validationLabels)\n    \n    print(\"Validation Loss:\", loss)\n    print(\"Validation Accuracy:\", accuracy)\n    \n    \ndef createSubmission(model, testImages):\n    predicted = model.predict(testImages)\n    predicted_classes = np.argmax(predicted, axis=1)\n    f = open(\"submissionFinal.csv\", \"w\")\n    f.write(\"Image,Class\\n\")\n    for i in range(len(testImages)):\n        string = str(testImageNames[i]).rstrip('\\n') + \",\" + str(predicted_classes[i]).rstrip('\\n') + \"\\n\"\n        f.write(string)\n    f.close()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T18:38:03.991839Z","iopub.execute_input":"2023-06-20T18:38:03.992201Z","iopub.status.idle":"2023-06-20T18:38:04.000018Z","shell.execute_reply.started":"2023-06-20T18:38:03.992171Z","shell.execute_reply":"2023-06-20T18:38:03.998740Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(testImageNames[2])","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:29:16.699486Z","iopub.status.idle":"2023-06-20T16:29:16.700564Z","shell.execute_reply.started":"2023-06-20T16:29:16.700313Z","shell.execute_reply":"2023-06-20T16:29:16.700338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='gelu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.45))\nmodel.add(layers.Dense(96, activation='sigmoid'))\n\n\n#%%\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=20, validation_data=(validationImages, validationLabels),verbose=0)\n\n\n\nvalidate(model, validationImages, validationLabels)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T18:59:20.006746Z","iopub.execute_input":"2023-06-20T18:59:20.007877Z","iopub.status.idle":"2023-06-20T18:59:51.624302Z","shell.execute_reply.started":"2023-06-20T18:59:20.007839Z","shell.execute_reply":"2023-06-20T18:59:51.622959Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 4ms/step - loss: 1.2305 - accuracy: 0.6480\nValidation Loss: 1.2304561138153076\nValidation Accuracy: 0.6480000019073486\n","output_type":"stream"}]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=20, validation_data=(validationImages, validationLabels),verbose=0)\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T19:04:07.448237Z","iopub.execute_input":"2023-06-20T19:04:07.448808Z","iopub.status.idle":"2023-06-20T19:04:36.130664Z","shell.execute_reply.started":"2023-06-20T19:04:07.448767Z","shell.execute_reply":"2023-06-20T19:04:36.129595Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 3ms/step - loss: 2.0590 - accuracy: 0.6270\nValidation Loss: 2.0589864253997803\nValidation Accuracy: 0.6269999742507935\n","output_type":"stream"}]},{"cell_type":"code","source":"#all gelu\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='gelu'))#gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='gelu'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=20, validation_data=(validationImages, validationLabels),verbose=0)\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T18:42:24.100034Z","iopub.execute_input":"2023-06-20T18:42:24.100411Z","iopub.status.idle":"2023-06-20T18:43:48.976371Z","shell.execute_reply.started":"2023-06-20T18:42:24.100382Z","shell.execute_reply":"2023-06-20T18:43:48.975364Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 6ms/step - loss: 2.4247 - accuracy: 0.6390\nValidation Loss: 2.4247043132781982\nValidation Accuracy: 0.6389999985694885\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#end with relu\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='gelu'))#gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=20, validation_data=(validationImages, validationLabels),verbose=0)\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T19:11:41.766628Z","iopub.execute_input":"2023-06-20T19:11:41.767762Z","iopub.status.idle":"2023-06-20T19:12:26.430623Z","shell.execute_reply.started":"2023-06-20T19:11:41.767712Z","shell.execute_reply":"2023-06-20T19:12:26.429336Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 8ms/step - loss: 2.3643 - accuracy: 0.6090\nValidation Loss: 2.364319324493408\nValidation Accuracy: 0.609000027179718\n","output_type":"stream"}]},{"cell_type":"code","source":"#end with gelu\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu')) \nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='gelu'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=20, validation_data=(validationImages, validationLabels),verbose=0)\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T19:13:26.847645Z","iopub.execute_input":"2023-06-20T19:13:26.848808Z","iopub.status.idle":"2023-06-20T19:14:10.737128Z","shell.execute_reply.started":"2023-06-20T19:13:26.848755Z","shell.execute_reply":"2023-06-20T19:14:10.736171Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 3ms/step - loss: 2.3243 - accuracy: 0.6240\nValidation Loss: 2.3243319988250732\nValidation Accuracy: 0.6240000128746033\n","output_type":"stream"}]},{"cell_type":"code","source":"#endalternate gelu and relu\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=40, validation_data=(validationImages, validationLabels),verbose=0)\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T19:14:58.817082Z","iopub.execute_input":"2023-06-20T19:14:58.817440Z","iopub.status.idle":"2023-06-20T19:16:23.805205Z","shell.execute_reply.started":"2023-06-20T19:14:58.817410Z","shell.execute_reply":"2023-06-20T19:16:23.804150Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 4ms/step - loss: 2.1911 - accuracy: 0.6980\nValidation Loss: 2.1911439895629883\nValidation Accuracy: 0.6980000138282776\n","output_type":"stream"}]},{"cell_type":"code","source":"#endalternate gelu and relu\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='swish'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=40, validation_data=(validationImages, validationLabels),verbose=0)\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T19:18:25.638279Z","iopub.execute_input":"2023-06-20T19:18:25.638640Z","iopub.status.idle":"2023-06-20T19:19:41.682321Z","shell.execute_reply.started":"2023-06-20T19:18:25.638609Z","shell.execute_reply":"2023-06-20T19:19:41.681337Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 0s 4ms/step - loss: 2.1156 - accuracy: 0.6960\nValidation Loss: 2.1155507564544678\nValidation Accuracy: 0.6959999799728394\n","output_type":"stream"}]},{"cell_type":"code","source":"# dropoutlayer 40 epoch without = 68\n# dropout 0.25 4 epoch = 67.5\n# dropout 0.69 4 epoch = 73.6\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.69))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=40,verbose=0)\n\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T19:33:25.349905Z","iopub.execute_input":"2023-06-20T19:33:25.350306Z","iopub.status.idle":"2023-06-20T19:34:41.960353Z","shell.execute_reply.started":"2023-06-20T19:33:25.350274Z","shell.execute_reply":"2023-06-20T19:34:41.959378Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"2023-06-20 19:33:27.659144: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_12/dropout_3/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"32/32 [==============================] - 0s 4ms/step - loss: 1.1061 - accuracy: 0.7530\nValidation Loss: 1.1061218976974487\nValidation Accuracy: 0.753000020980835\n","output_type":"stream"}]},{"cell_type":"code","source":"# dropout 69 80 epoch = 76\n# dropout 75 80 epoch = 75\n# dropout 72 80 epoch = 76.4\n# dropout 55 80 epoch = 75\n# dropout 65 80 epoch = 73\n# dropout 31 80 epoch = 69\n\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.72))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=40,verbose=0)\n\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:38:08.770552Z","iopub.execute_input":"2023-06-20T16:38:08.770939Z","iopub.status.idle":"2023-06-20T16:41:33.462226Z","shell.execute_reply.started":"2023-06-20T16:38:08.770904Z","shell.execute_reply":"2023-06-20T16:41:33.461302Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"2023-06-20 16:38:11.035947: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout_4/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"32/32 [==============================] - 0s 4ms/step - loss: 1.1649 - accuracy: 0.7650\nValidation Loss: 1.1649032831192017\nValidation Accuracy: 0.7649999856948853\n","output_type":"stream"}]},{"cell_type":"code","source":"# dropout 72 after dense 0.748\n# dropout before and after 50+25 = 0.746\n# dropout before and after 72+25 = 0.7849\n# dropout before and after 72+25 120 epochs = 0.796\n# dropout before and after 72+25 40 epochs = .778\n# dropout before and after 72+25 40 epochs + swish dense= 765\n# dropout before and after 72+25 40 epochs + swish 2d= 757\n# dropout before and after 72+25 40 epochs + swish 2*2d= 768\n# dropout before and after 72+25 40 epochs + swish 3*2d= 75\n# dropout before and after 72+20 40 epochs + swish + gelu + swish= 73\n# dropout before and after 72+20 40 epochs + swish + relu + swish= \n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='swish', input_shape=(64, 64, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='swish')) #gelu\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.72))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.20))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=40,verbose=1)\n\n\n\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:29:16.722276Z","iopub.status.idle":"2023-06-20T16:29:16.723563Z","shell.execute_reply.started":"2023-06-20T16:29:16.722961Z","shell.execute_reply":"2023-06-20T16:29:16.722985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch normalization\n#  III => 0.623\n#  all -> 0,763\n# all + relu -> 0.72\n# all 120 - 0.75\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.72))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(96, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=120,verbose=1)\n\n\n\n\nvalidate(model, validationImages, validationLabels)\n\npredicted = model.predict(validationImages)\npredicted_classes = np.argmax(predicted, axis=1)\n\nconfusionMatrix = np.zeros((96, 96))\nfor i in range(len(validationImages)):\n    confusionMatrix[validationLabels[i],predicted_classes[i]] += 1\n    \nplt.figure(figsize=(10,10))\nplt.matshow(confusionMatrix,cmap='PRGn')\nplt.colorbar()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:30:07.148929Z","iopub.execute_input":"2023-06-20T16:30:07.149297Z","iopub.status.idle":"2023-06-20T16:35:33.827257Z","shell.execute_reply.started":"2023-06-20T16:30:07.149262Z","shell.execute_reply":"2023-06-20T16:35:33.825692Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/120\n","output_type":"stream"},{"name":"stderr","text":"2023-06-20 16:30:10.336657: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"188/188 [==============================] - 13s 14ms/step - loss: 4.3210 - accuracy: 0.0831\nEpoch 2/120\n188/188 [==============================] - 3s 14ms/step - loss: 3.2444 - accuracy: 0.2260\nEpoch 3/120\n188/188 [==============================] - 3s 13ms/step - loss: 2.5176 - accuracy: 0.3399\nEpoch 4/120\n188/188 [==============================] - 3s 13ms/step - loss: 2.1033 - accuracy: 0.4236\nEpoch 5/120\n188/188 [==============================] - 3s 13ms/step - loss: 1.8213 - accuracy: 0.4818\nEpoch 6/120\n188/188 [==============================] - 3s 14ms/step - loss: 1.6534 - accuracy: 0.5199\nEpoch 7/120\n188/188 [==============================] - 3s 13ms/step - loss: 1.5284 - accuracy: 0.5508\nEpoch 8/120\n188/188 [==============================] - 3s 13ms/step - loss: 1.3662 - accuracy: 0.5972\nEpoch 9/120\n188/188 [==============================] - 3s 13ms/step - loss: 1.2936 - accuracy: 0.6081\nEpoch 10/120\n188/188 [==============================] - 3s 14ms/step - loss: 1.2100 - accuracy: 0.6321\nEpoch 11/120\n188/188 [==============================] - 3s 13ms/step - loss: 1.1434 - accuracy: 0.6532\nEpoch 12/120\n188/188 [==============================] - 3s 13ms/step - loss: 1.0928 - accuracy: 0.6643\nEpoch 13/120\n188/188 [==============================] - 3s 13ms/step - loss: 1.0241 - accuracy: 0.6807\nEpoch 14/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.9736 - accuracy: 0.6957\nEpoch 15/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.9354 - accuracy: 0.7116\nEpoch 16/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.8956 - accuracy: 0.7155\nEpoch 17/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.8763 - accuracy: 0.7234\nEpoch 18/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.8058 - accuracy: 0.7415\nEpoch 19/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.7855 - accuracy: 0.7448\nEpoch 20/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.7652 - accuracy: 0.7514\nEpoch 21/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.7494 - accuracy: 0.7599\nEpoch 22/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.7048 - accuracy: 0.7720\nEpoch 23/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.6921 - accuracy: 0.7757\nEpoch 24/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.6707 - accuracy: 0.7878\nEpoch 25/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.6487 - accuracy: 0.7856\nEpoch 26/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.6381 - accuracy: 0.7905\nEpoch 27/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.6056 - accuracy: 0.8015\nEpoch 28/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.5993 - accuracy: 0.8049\nEpoch 29/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.5718 - accuracy: 0.8179\nEpoch 30/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.5518 - accuracy: 0.8210\nEpoch 31/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.5633 - accuracy: 0.8155\nEpoch 32/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.5285 - accuracy: 0.8267\nEpoch 33/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.5236 - accuracy: 0.8257\nEpoch 34/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.5052 - accuracy: 0.8329\nEpoch 35/120\n188/188 [==============================] - 3s 15ms/step - loss: 0.5099 - accuracy: 0.8361\nEpoch 36/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.5101 - accuracy: 0.8332\nEpoch 37/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.4952 - accuracy: 0.8403\nEpoch 38/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.4801 - accuracy: 0.8363\nEpoch 39/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.4796 - accuracy: 0.8462\nEpoch 40/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.4846 - accuracy: 0.8405\nEpoch 41/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.4721 - accuracy: 0.8456\nEpoch 42/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.4442 - accuracy: 0.8562\nEpoch 43/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.4443 - accuracy: 0.8513\nEpoch 44/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4277 - accuracy: 0.8595\nEpoch 45/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.4275 - accuracy: 0.8626\nEpoch 46/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.4038 - accuracy: 0.8691\nEpoch 47/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.4209 - accuracy: 0.8612\nEpoch 48/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.4056 - accuracy: 0.8649\nEpoch 49/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.4131 - accuracy: 0.8617\nEpoch 50/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3968 - accuracy: 0.8712\nEpoch 51/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3975 - accuracy: 0.8640\nEpoch 52/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3781 - accuracy: 0.8703\nEpoch 53/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3735 - accuracy: 0.8785\nEpoch 54/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3700 - accuracy: 0.8782\nEpoch 55/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3548 - accuracy: 0.8822\nEpoch 56/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3613 - accuracy: 0.8788\nEpoch 57/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.3402 - accuracy: 0.8887\nEpoch 58/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3450 - accuracy: 0.8839\nEpoch 59/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3433 - accuracy: 0.8857\nEpoch 60/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.3121 - accuracy: 0.8925\nEpoch 61/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3198 - accuracy: 0.8878\nEpoch 62/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3320 - accuracy: 0.8878\nEpoch 63/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3312 - accuracy: 0.8896\nEpoch 64/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3287 - accuracy: 0.8917\nEpoch 65/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.3236 - accuracy: 0.8913\nEpoch 66/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3334 - accuracy: 0.8885\nEpoch 67/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3063 - accuracy: 0.8960\nEpoch 68/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3026 - accuracy: 0.8980\nEpoch 69/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.3125 - accuracy: 0.8971\nEpoch 70/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2998 - accuracy: 0.8978\nEpoch 71/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2827 - accuracy: 0.9063\nEpoch 72/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2907 - accuracy: 0.9043\nEpoch 73/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2935 - accuracy: 0.9020\nEpoch 74/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2696 - accuracy: 0.9118\nEpoch 75/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2929 - accuracy: 0.9048\nEpoch 76/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2717 - accuracy: 0.9087\nEpoch 77/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2772 - accuracy: 0.9087\nEpoch 78/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2905 - accuracy: 0.9046\nEpoch 79/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2625 - accuracy: 0.9097\nEpoch 80/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2624 - accuracy: 0.9115\nEpoch 81/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2679 - accuracy: 0.9107\nEpoch 82/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2629 - accuracy: 0.9112\nEpoch 83/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2605 - accuracy: 0.9129\nEpoch 84/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2572 - accuracy: 0.9156\nEpoch 85/120\n188/188 [==============================] - 3s 15ms/step - loss: 0.2454 - accuracy: 0.9162\nEpoch 86/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2655 - accuracy: 0.9121\nEpoch 87/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2385 - accuracy: 0.9193\nEpoch 88/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2413 - accuracy: 0.9201\nEpoch 89/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2428 - accuracy: 0.9183\nEpoch 90/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2423 - accuracy: 0.9185\nEpoch 91/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2549 - accuracy: 0.9162\nEpoch 92/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2373 - accuracy: 0.9216\nEpoch 93/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2569 - accuracy: 0.9135\nEpoch 94/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2471 - accuracy: 0.9177\nEpoch 95/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2285 - accuracy: 0.9262\nEpoch 96/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2243 - accuracy: 0.9238\nEpoch 97/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2330 - accuracy: 0.9233\nEpoch 98/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2332 - accuracy: 0.9232\nEpoch 99/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2338 - accuracy: 0.9219\nEpoch 100/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2244 - accuracy: 0.9270\nEpoch 101/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2316 - accuracy: 0.9217\nEpoch 102/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2186 - accuracy: 0.9262\nEpoch 103/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2224 - accuracy: 0.9256\nEpoch 104/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2232 - accuracy: 0.9258\nEpoch 105/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2276 - accuracy: 0.9228\nEpoch 106/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2119 - accuracy: 0.9295\nEpoch 107/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2063 - accuracy: 0.9282\nEpoch 108/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2221 - accuracy: 0.9247\nEpoch 109/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2029 - accuracy: 0.9323\nEpoch 110/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2166 - accuracy: 0.9287\nEpoch 111/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2009 - accuracy: 0.9301\nEpoch 112/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.1975 - accuracy: 0.9355\nEpoch 113/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2023 - accuracy: 0.9323\nEpoch 114/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.1918 - accuracy: 0.9340\nEpoch 115/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2023 - accuracy: 0.9300\nEpoch 116/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2031 - accuracy: 0.9308\nEpoch 117/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2049 - accuracy: 0.9328\nEpoch 118/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.1916 - accuracy: 0.9360\nEpoch 119/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.1958 - accuracy: 0.9349\nEpoch 120/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.1873 - accuracy: 0.9344\n32/32 [==============================] - 0s 6ms/step - loss: 0.9258 - accuracy: 0.7530\nValidation Loss: 0.9257735013961792\nValidation Accuracy: 0.753000020980835\n32/32 [==============================] - 0s 3ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 480x480 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAZkAAAGVCAYAAAAsZ4y1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyIUlEQVR4nO3dfXRU5b0v8O+eRIYgk6HIyUxyCTTUKEh8oQRzCGiCNbmN4hJplYIiaK83rgRqnIW81jpSmTGoOTkFiYbbC7FtNLenUlkWMWmRAOVwCFEKIoLWFFJlThYszATExGT2/QOz2ZMXmJk9e+aZPd8Pa9Z6Zs/svZ89M/Dj+T0vW5JlWQYREZEOTNGuABERGReDDBER6YZBhoiIdMMgQ0REumGQISIi3TDIEBGRbhhkiIhINwwyRESkGwYZIiLSDYMMERHphkGGiCgOVVVV4aabbkJycjKSk5MxdepUvPPOO8rrsizD6XQiLS0NSUlJyM/Px5EjR4I+D4MMEVEcGj16NJ5//nkcOHAABw4cwB133IF7771XCSRr165FRUUF1q9fj6amJtjtdhQUFKCjoyOo80hcIJOIiABg5MiReOGFF/Doo48iLS0NZWVlWLZsGQCgs7MTNpsN5eXlKC4uDviYiXpVloiIAvP111+jq6tL83FkWYYkSX7bzGYzzGbzZffr6enB73//e5w/fx5Tp05FS0sLPB4PCgsL/Y6Tl5eHvXv3MsgQEcWKr7/+GknWq4Eun+ZjDR8+HOfOnfPb9swzz8DpdA74/sOHD2Pq1Kn4+uuvMXz4cGzZsgU33HAD9u7dCwCw2Wx+77fZbDhx4kRQdWKQISKKoq6urosB5nY7kKihm7zbh3O7PGhtbUVycrKy+XKtmOuvvx4HDx7El19+iT/84Q9YsGABGhsbldf7tooGaildCYMMEZEApCEJkDQEGdkkQQaU0WKBGDJkCK699loAQHZ2NpqamvDv//7vSj+Mx+NBamqq8v62trZ+rZsr4egyIiICcLGl0tnZiYyMDNjtdjQ0NCivdXV1obGxEbm5uUEdky0ZIiIBSJIEyRRcKqrPARDMUOGVK1eiqKgI6enp6OjowBtvvIGdO3di+/btkCQJZWVlcLlcyMzMRGZmJlwuF4YNG4Z58+YFVS0GGSIiAUgmjUEmyH3/+7//G/Pnz8epU6dgtVpx0003Yfv27SgoKAAALF26FBcuXEBJSQnOnj2LnJwc1NfXw2KxBHUezpMhIooir9cLq9WKhP+ZDukqDX0y3/jQ824r2tvbA+6TiQS2ZIiIBBDplkykMMgQEQlAMpkgmTSMxRJ0GJeg1SIiIiNgS4aISABMlxERkW6MGmSYLiMiIt2wJUNEJACTCZpaMrKgTQYGGSIiATBdFkEbNmxARkYGhg4dismTJ2P37t3RrlJYud1uTJkyBRaLBSkpKZg1axaOHTvm955w3fpUZG63W1m+opdRr/vzzz/HQw89hGuuuQbDhg3DLbfcgubmZuV1I153d3c3fv7znyMjIwNJSUkYN24cVq9eDZ/v0pL2RrzuUPUGGS0PEQkXZOrq6lBWVoZVq1bhgw8+wG233YaioiKcPHky2lULm8bGRpSWlmLfvn1oaGhAd3c3CgsLcf78eeU94br1qaiamppQXV2Nm266yW+7Ea/77NmzmDZtGq666iq88847+Oijj/DSSy9hxIgRynuMeN3l5eV45ZVXsH79ehw9ehRr167FCy+8gHXr1invMeJ1Ux+yYG699Vb58ccf99s2fvx4efny5VGqkf7a2tpkAHJjY6Msy7Ls8/lku90uP//888p7vv76a9lqtcqvvPJKtKoZNh0dHXJmZqbc0NAg5+XlyU888YQsy8a97mXLlsnTp08f9HWjXvfdd98tP/roo37bZs+eLT/00EOyLBv3uoPV3t4uA5CHP5ApWx4aH/Jj+AOZMgC5vb092pfkR6iWTFdXF5qbm/1u+QkAhYWFyp3ajKi9vR3AxftrA7jirU9jXWlpKe6++27ceeedftuNet1bt25FdnY27r//fqSkpGDSpEnYuHGj8rpRr3v69On4y1/+guPHjwMA/va3v2HPnj246667ABj3ukMlJUiaHyISquP/9OnT6OnpGfCWnx6PJ0q10pcsy3A4HJg+fTqysrIAQLnWcNz6VDRvvPEG3n//fTQ1NfV7zajX/dlnn6GqqgoOhwMrV67E/v378bOf/QxmsxkPP/ywYa972bJlaG9vx/jx45GQkICenh6sWbMGc+fOBWDc75v8CRVkeoXjlp+xYtGiRTh06BD27NnT7zWjfQ6tra144oknUF9fj6FDhw76PqNdt8/nQ3Z2NlwuFwBg0qRJOHLkCKqqqvDwww8r7zPaddfV1eG3v/0tamtrMXHiRBw8eBBlZWVIS0vDggULlPcZ7bpDxdFlETBq1CgkJCT0a7WEcsvPWLB48WJs3boV7733HkaPHq1st9vtAGC4z6G5uRltbW2YPHkyEhMTkZiYiMbGRvzqV79CYmKicm1Gu+7U1FTccMMNftsmTJigDGYx6vf91FNPYfny5fjJT36CG2+8EfPnz8eTTz4Jt9sNwLjXHSqOLouAIUOGYPLkyX63/ASAhoaGoG/5KTJZlrFo0SK8+eab2LFjBzIyMvxeD+etT0Xygx/8AIcPH8bBgweVR3Z2Nh588EEcPHgQ48aNM+R1T5s2rd8Q9ePHj2Ps2LEAjPt9f/XVVzD1WVU4ISFBGcJs1Osmf8KlyxwOB+bPn4/s7GxMnToV1dXVOHnyJB5//PFoVy1sSktLUVtbi7feegsWi0X5n5zVakVSUlJYb30qEovFovQ79br66qtxzTXXKNuNeN1PPvkkcnNz4XK58MADD2D//v2orq5GdXU1ABj2+77nnnuwZs0ajBkzBhMnTsQHH3yAiooKPProowCMe92h0r7Uv5j3nxQuyMyZMwdnzpzB6tWrcerUKWRlZWHbtm3K//qMoKqqCgCQn5/vt33Tpk1YuHAhgPDd+jTWGPG6p0yZgi1btmDFihVYvXo1MjIyUFlZiQcffFB5jxGve926dXj66adRUlKCtrY2pKWlobi4GL/4xS+U9xjxukNl1D4Z3n6ZiCiKem+//J1HJkIakhDyceSuHpzddIS3XyYiogFobMnIgrZkGGSIiASgNV3G0WVERBR32JIhIhKAUVsyDDJERAKQJI1BRtBVEhhkiIgEYNSWjLB9Mp2dnXA6nejs7Ix2VSKK183rjgfxet3xSNh5Mr1jx0Ub8603XjevOx7E63UPpPezSFk0CSZz6PNkfJ09aFv/gXCfKdNlREQCYLosSBs2bEBGRgaGDh2KyZMnY/fu3XqdioiIBKVLS6aurg5lZWXYsGEDpk2bhldffRVFRUX46KOPMGbMmMvu6/P58MUXX6A3i+f1evWoorB6r5fXHR943bF53bIso6OjA2lpaf1Wmg6VUVsyuvTJ5OTk4Pvf/76yECRw8f4Zs2bNUu4l0auzs9Ov8+/zzz/vd+8NIiIRtba2+t0LKhS9fTJpjmyYzKH/v9/X2Y0vKg4Yv0+mq6sLzc3NWL58ud/2wsLCAe/b7Xa78eyzz/bbfuivh2AZbsH8m4vDXUUiIk260Y192BGXq0UHK+xB5vTp0+jp6Rnwvt1974AHACtWrIDD4VCee71epKeno2TaEiTiKswve0x57fXKzeGubtiNsHxHKX/ZcTbu6yGiUD6ba0dnKuVP//lJ2OtEkaH+7vsK5e9JOCdAJpgkmAyYLtNtdFmg9+02m80wm816VYOIKCaYTCZt/Tth6hsKt7DXatSoUUhISOB9u4mIKPwtmSFDhmDy5MloaGjAfffdp2xvaGjAvffeG/Tx1Cmy1z/8tVKem/VTTfXUiyipKVHqMZhopvNCOR9TZGIK9nck8t+LBI0tGU23btaRLukyh8OB+fPnIzs7G1OnTkV1dTVOnjyJxx9/XI/TERHFPMkkwZTAm5YFZM6cOThz5gxWr16NU6dOISsrC9u2bcPYsWP1OB0REQlKt47/kpISlJSUhPWY6hRZLKTOaHAipy3oykQZvWik31GCyYQEA3b8c+0yIiIBaB1dJjPIEBHRYBJMEhK09KvEU59MJKhTZM/+5pd+r/1mxWtKmaOCiMLPSGkq0lfMBhkiIiNhuoyIiHRj1CAjZq2IiMgQDNGSaXr7fb/n46dlKeVP69gnQ0RXFu1h2ez4JyIi3UgmSVO6zCdokGG6jIiIdGOIlszbdVsGfc3I9wHpe28M0YeVzphRoJTfe68hqH1j7Vop8rSmu6L9m0qQtM34lyUx2wyGCDJERLHOlKBtgUwt++pJzNBHRESGYPiWjDpF9pizVClvdL4cjeqEVbSb98FSp8hEvA9ItEcXkT8RfyN60rpAZrDzZNxuN9588018/PHHSEpKQm5uLsrLy3H99dcr71m4cCFqamr89svJycG+ffsCPg9bMkREAuidjKnlEYzGxkaUlpZi3759aGhoQHd3NwoLC3H+/Hm/9/3whz/EqVOnlMe2bduCOo/hWzJERNTf9u3b/Z5v2rQJKSkpaG5uxu23365sN5vNsNvtIZ8nroKMOkWWPeFWpaxuZhttBJqoRExt6FUnI49w1JP6+5hbtlApq2/JbiRaJ2P23hnT6/X6bTebzTCbzVfcv729HQAwcuRIv+07d+5ESkoKRowYgby8PKxZswYpKSkB14vpMiIiAYQrXZaeng6r1ao83G73Fc8tyzIcDgemT5+OrKxLK6YUFRXhd7/7HXbs2IGXXnoJTU1NuOOOO9DZ2RnwdcVVS4aISFQmjS2Z3hn/ra2tSE5OVrYH0opZtGgRDh06hD179vhtnzNnjlLOyspCdnY2xo4diz/96U+YPXt2QPWK2yBz4Oh+paxuin9ayXQGhZdeKbJ4Gg1n1BSZHpKTk/2CzJUsXrwYW7duxa5duzB69OjLvjc1NRVjx47FJ58E/puO2yBDRCQSrUv9B7uvLMtYvHgxtmzZgp07dyIjI+OK+5w5cwatra1ITU0N+DwMMkREAtA6T8YX5L6lpaWora3FW2+9BYvFAo/HAwCwWq1ISkrCuXPn4HQ68aMf/Qipqan4xz/+gZUrV2LUqFG47777Aj4Pgwz8m+Kv7l6vlItvWxSF2hAFxugpMtJXVVUVACA/P99v+6ZNm7Bw4UIkJCTg8OHDeO211/Dll18iNTUVM2bMQF1dHSwWS8DnYZAhIhKAyaRx7bIgBw3IsnzZ15OSkvDuu++GXJ9eDDJERAK4OE/GePeTETbIjEv7HoaYzBGfvLbsrqeVcihL06sneapHsBHFM60j4eJpJJ3RCBtkiIjiSaRHl0UKgwwRkQC0LivDdFmQPvvi70jEVRE/r7oprk6RLVm3XCnv3LBDKfdNiTFFRhR+TJHFLmGDDBFRPGG6jIiIdGPSOBmzh0Emtr24+HmlPHOOarbr0ShUhijGMN0VvxhkiIgEkGBKQIIpQdP+ImKQISISQIJkQoIUespLy756YpAJwdt1W5Ryxdsv+r3mmLkk0tWhCODdLUlvRm3JiBn6iIjIENiSISISQIKkbXQZ02VERDSoi/eT0ZIuY5AJinX4CFwlDRF+6GPfPhh1H02k+2e4iCARiUbYIENEFE9MGkeXmZguIyKiwRh1dJmwQab93JdRWSBTK3WKTL2opnrFAL0MliJjGk07vYct8zsioxI2yBARxZMEjWuXseOfiIgGxXQZBW2wRTXVKwZEAtMv4qejRKwTUTgwyBARCYBrlxERkW6YLiNN1Cmy1z/8tVKem/XTaFQnYkRZWJLpqPgieno0njDIEBEJwGSSNI0QM5mkMNYmfBhkiIgEwHQZhY06Rfbq7vVKufi2RdGoTtipUxW89woBkU9fxWKKzKgd/2LWioiIDCGoION2uzFlyhRYLBakpKRg1qxZOHbsmN97ZFmG0+lEWloakpKSkJ+fjyNHjoS10kRERpMgJSgps5AekgHSZY2NjSgtLcWUKVPQ3d2NVatWobCwEB999BGuvvpqAMDatWtRUVGBzZs347rrrsNzzz2HgoICHDt2DBaLRZeLiGXqFNm2r36vlO8adn80qhMWsZiqIH3xN3FlXFYGwPbt2/2eb9q0CSkpKWhubsbtt98OWZZRWVmJVatWYfbs2QCAmpoa2Gw21NbWori4uN8xOzs70dnZqTz3er2hXAcREQlIU+hrb28HAIwcORIA0NLSAo/Hg8LCQuU9ZrMZeXl52Lt374DHcLvdsFqtyiM9PV1LlYiIYlJvS0bLQ0Qhjy6TZRkOhwPTp09HVlYWAMDj8QAAbDab33ttNhtOnDgx4HFWrFgBh8OhPPd6vXEbaNQpMiOOOtNCPToJYPqFjMekcQizyWhDmBctWoRDhw5hz549/V6TJP9JQbIs99vWy2w2w2w2h1oNIiISWEhBZvHixdi6dSt27dqF0aNHK9vtdjuAiy2a1NRUZXtbW1u/1g0REV2SIEka58kYYMa/LMtYvHgxtmzZgp07dyIjI8Pv9YyMDNjtdjQ0NGDSpEkAgK6uLjQ2NqK8vDx8tY4D6hTZf3xWo5R/PG5BNKoTdUyPkdFxxj+A0tJS1NbW4q233oLFYlH6YKxWK5KSkiBJEsrKyuByuZCZmYnMzEy4XC4MGzYM8+bN0+UCiIhIXEEFmaqqKgBAfn6+3/ZNmzZh4cKFAIClS5fiwoULKCkpwdmzZ5GTk4P6+nrOkSEiugzOk8HFdNmVSJIEp9MJp9MZap2oD3WKrOLtF5WyY+aSaFSHiHTAdBkREemGC2QSEREFiS2ZGKNOkS1Zt9zvtRcXPx/p6pAGgS5/z7s8Bi8WPzNOxiQiIt2YYIJJQ8rLJGhiSsxaERGRIbAlQ0QkAJOksSUjaMc/g0wM69sH85izVCn//qVapRwrOel4E+j3Mso6Kuh94l0sfk4mSdIYZMRcVkbM0EdERIbAlgwRkQCYLiPhbXS+rJSf/c0vlfIz85+ORnUMJXvCrUr5wNH9YTlmoMNsT7efDsv5SGxGDTJi1oqIiAyBLRkiIgEYtSUjbJAZl/Y9DDGZ8ek/P4l2VWKSOkW2886DSjn/z7dEvjIC0DoDXI/foV4joGJxtjt9OxlTQ3Ip2H3dbjfefPNNfPzxx0hKSkJubi7Ky8tx/fXXK++RZRnPPvssqqurlVX1X375ZUycODGIehERUdxpbGxEaWkp9u3bh4aGBnR3d6OwsBDnz59X3rN27VpUVFRg/fr1aGpqgt1uR0FBATo6OgI+j7AtGSKieBLpdNn27dv9nm/atAkpKSlobm7G7bffDlmWUVlZiVWrVmH27NkAgJqaGthsNtTW1qK4uDig8wgbZD774u9IxFXRroYhqFNk8XorZ61po2imnYI9N1Nk/mIlfShpDDLSt/t6vV6/7WazGWaz+Yr7t7e3AwBGjhwJAGhpaYHH40FhYaHfsfLy8rB3796AgwzTZUREAuhtyWh5AEB6ejqsVqvycLvdVzy3LMtwOByYPn06srKyAAAejwcAYLPZ/N5rs9mU1wIhbEuGiIiC19raiuTkZOV5IK2YRYsW4dChQ9izZ0+/16Q+y9XIstxv2+UwyBjUtaMzlbJ6ZJQ6RabHBMNYEyupFApOLH6v4eqTSU5O9gsyV7J48WJs3boVu3btwujRo5XtdrsdwMUWTWpqqrK9ra2tX+vmsvUK+J1ERKQbEyRlGHNof4JbIFOWZSxatAhvvvkmduzYgYyMDL/XMzIyYLfb0dDQoGzr6upCY2MjcnNzAz4PWzJERHGotLQUtbW1eOutt2CxWJR+FqvViqSkJEiShLKyMrhcLmRmZiIzMxMulwvDhg3DvHnzAj4Pg4xBBTJ5UJ0imzGjQCm/917DQG83pFhJpVBwYvF7jfQQ5qqqKgBAfn6+3/ZNmzZh4cKFAIClS5fiwoULKCkpUSZj1tfXw2KxBHweBhkiIgFEOsjIsnzF90iSBKfTCafTGWKt2CdDREQ6YkuGAPinyHibAKLI4wKZRESkG6MGGTFrRUREhsCWDPWjTpHF66izWBCLEw5DNdjkYiMxakuGQYaISAC9UzG17C8iMWtFRESGYMiWTDylEfSmTpEtWbfc77UXFz8/4D78/CMjnj7bSKfIovEbZrqMiIh0wyBDRES6MUmSxiAT3AKZkSJm6CMiIkMwZEsmnnLVkTRYH0xfsfr5sy8pMkQZFq/+vgH/7zwa378JGtNlgrYZDBlkiIhijVH7ZMSsFRERGQJbMhQy9Szs0+2nlXIspZoikSJjGs5fh6c9aucW+bswaZyMyXQZERENiukyIiKiILElQyEbbBb2Y85Spfz7l2qVsmjpCcC/TnqlUkS87mhS3/Y70kT+LozakmGQISISgPTtHy37i0jM0EdERIbAlkwc0ys9tNH5slKeOec+pfx23ZawnUMPoqZSRB4RZSRR/5wlEyQtKS+my4iIaDAmSDBpSHlp2VdPYoY+IiIyBLZkYtjl1l4KRCRSAuoU2R/ObVbK7ikblHI0RxvFAqbIAqP1Fs3R/pylb9syWvYXEYMMEZEAjDq6jEGGiEgAkgRIGu4JI+jtZBhkYlm0m/fBUqfI7Df9j0svHL3yvlpTg2R8kb5FMwWGQYaISABG7ZPRVCu32w1JklBWVqZsk2UZTqcTaWlpSEpKQn5+Po4cOaK1nkREhiaF4Y+IQm7JNDU1obq6GjfddJPf9rVr16KiogKbN2/Gddddh+eeew4FBQU4duwYLBaL5gpT7PIbRaZKkaknbH781w+Vsjr9EYn0WNQn48UQflYUqJBaMufOncODDz6IjRs34jvfufRjk2UZlZWVWLVqFWbPno2srCzU1NTgq6++Qm1t7YDH6uzshNfr9XsQEcUbUxj+iCikWpWWluLuu+/GnXfe6be9paUFHo8HhYWFyjaz2Yy8vDzs3bt3wGO53W5YrVblkZ6eHkqViIhimiRJmh8iCjpd9sYbb+D9999HU1NTv9c8Hg8AwGaz+W232Ww4ceLEgMdbsWIFHA6H8tzr9QYdaNSTsACOMok1nkOfK+UZ/+vSf1A+der/PTLtExp+VhSooIJMa2srnnjiCdTX12Po0KGDvq9vRJVledAoazabYTabg6kGEZHhcHQZgObmZrS1tWHy5MlITExEYmIiGhsb8atf/QqJiYlKC6a3RdOrra2tX+uGiIgu4egyAD/4wQ9w+PBhv22PPPIIxo8fj2XLlmHcuHGw2+1oaGjApEmTAABdXV1obGxEeXl5+GrdB9NjsUed4lSPOjvgvFTOnnDrgO8JJ6Z9YhvTneILKshYLBZkZWX5bbv66qtxzTXXKNvLysrgcrmQmZmJzMxMuFwuDBs2DPPmzQtfrYmIDEZr571hOv6vZOnSpbhw4QJKSkpw9uxZ5OTkoL6+nnNkiIguw6h9MpIsy3K0K6Hm9XphtVoxHYVIxFXRrg4JQj1hExD/LpsUGep02SjrKKWsdwq9G99gD+rR3t6O5ORkTcfq/Tfv0y+Ow5Ic+n/GO7wduDbturDUKZy4dhkRkQCMemdMBhkiIgEYNV3GIENEJAKts/bjpeOfSA99+2Be3b1eKRfftijS1SFBqIctcwizmBhkiIgEwNsvExGRbi6GGC19MgwyFATOZL48dYrsMWepUt7ofDka1SGiQTDIEBEJgEOYiYhIN5JkgiRpSJdp2FdPDDKCYooscOoUGUedUV9MPUcXgwwRkQA4uoyIiHTDIEMUA9Qpsmd/80ul/Mz8p6NRHRIAU2SD27VrF1544QU0Nzfj1KlT2LJlC2bNmqW8vnDhQtTU1Pjtk5OTg3379gV8DjF7ioiI4kxvx7+WR7DOnz+Pm2++GevXrx/0PT/84Q9x6tQp5bFt27agzsGWDBGRAKKRLisqKkJRUdFl32M2m2G320OtFoMMGZc6RcZRZxQvvF6v33Oz2Qyz2Rzy8Xbu3ImUlBSMGDECeXl5WLNmDVJSUgLen+kyIiIBSLKk+QEA6enpsFqtysPtdodcp6KiIvzud7/Djh078NJLL6GpqQl33HEHOjs7Az4GWzJERAKQZRlablTcu29ra6vfnTG1tGLmzJmjlLOyspCdnY2xY8fiT3/6E2bPnh3QMRhkKC4su0tb6uza0ZlKWe9b+1J8kuWLDy37A0BycrJut19OTU3F2LFj8ckngf8dYLqMiIgCcubMGbS2tiI1NTXgfdiSISISgU+++NCyf5DOnTuHTz/9VHne0tKCgwcPYuTIkRg5ciScTid+9KMfITU1Ff/4xz+wcuVKjBo1Cvfdd1/A52CQCTOukyQm9XehTpEtWbdcKb+4+PlB92eKLPLi7e9SuPpkgnHgwAHMmDFDee5wOAAACxYsQFVVFQ4fPozXXnsNX375JVJTUzFjxgzU1dXBYrEEfA4GGSKiOJWfn3/Z4PTuu+9qPgeDDBGRCHzfPrTsLyAGmTCLh2a9kfyfla8q5ewJtyrlA0f3R6M6pBJvf5eikS6LBI4uIyIi3bAlQ0QkgHDNkxENgwxFjHpC4+n200o5mmkR9bnVKbIZMwr83vfeew0RqxPFKVnjEGZBowzTZUREpBu2ZIiIBGDUjn8GGSIiAbBPhgISb7OUgxFLs+b79sHwfjSkuygsKxMJ7JMhIiLdsCVDRCQApssoIEyRRUak05LqFNljzlKlvNH5su7npjjBdBkREVFw2JIhIhIAhzATCSSaaUl1iqzi7ReV8uq5a5Qy06bG1Jum/UbuAs6F99hG7ZNhuoyIiHTDlgwRkQgM2vFv+CCj9ygk9aKPQGxNOIxlokx6dcxcopRnzrl03/O367ZEozqks97fWje+Cf/BNabLIGaMYbqMiIj0Y/iWDBFRLLjY8a9ldFkYKxNGhg8yeqdSjJIeEyX9FCgR66hOkTF1Fhmx9ru9LN+3Dy37C4jpMiIi0o3hWzJERLGAkzENwFBN6zDj5xFe6hTZ6x/+WinPzfppNKpjWIb63Rr09stxFWSIiETFGf9ERERBiqmWjNZ0l6Ga1hQz1Cky3iaABsM+GSIi0g+HMF/0+eef46GHHsI111yDYcOG4ZZbbkFzc7PyuizLcDqdSEtLQ1JSEvLz83HkyJGwVpqIiGJDUC2Zs2fPYtq0aZgxYwbeeecdpKSk4O9//ztGjBihvGft2rWoqKjA5s2bcd111+G5555DQUEBjh07BovFoqmyIqa71Ck8QJw6BpJa5Gi7wGVPuFUpHzi6P+TjqFNkTJ2RGtNlAMrLy5Geno5NmzYp27773e8qZVmWUVlZiVWrVmH27NkAgJqaGthsNtTW1qK4uLjfMTs7O9HZ2ak893q9wV4DEVHMk30yZA1DmLXsq6eg0mVbt25FdnY27r//fqSkpGDSpEnYuHGj8npLSws8Hg8KCwuVbWazGXl5edi7d++Ax3S73bBarcojPT09xEshIiLRBNWS+eyzz1BVVQWHw4GVK1di//79+NnPfgaz2YyHH34YHo8HAGCz2fz2s9lsOHHixIDHXLFiBRwOh/Lc6/XGVKDpu9S/llRKOAWS/mKKLHB6fK9MnYkl2uljn0+GT0NrRMu+egoqyPh8PmRnZ8PlcgEAJk2ahCNHjqCqqgoPP/yw8j5Jkvz2k2W537ZeZrMZZrM52HoTERkK02UAUlNTccMNN/htmzBhAk6ePAkAsNvtAKC0aHq1tbX1a90QEZHxBdWSmTZtGo4dO+a37fjx4xg7diwAICMjA3a7HQ0NDZg0aRIAoKurC42NjSgvLw9TlcUiSnqMYttgqbO+r8WrSKSyop0+9skyfBpGiGnZV09BBZknn3wSubm5cLlceOCBB7B//35UV1ejuroawMU0WVlZGVwuFzIzM5GZmQmXy4Vhw4Zh3rx5ulwAEZERGDVdFlSQmTJlCrZs2YIVK1Zg9erVyMjIQGVlJR588EHlPUuXLsWFCxdQUlKCs2fPIicnB/X19ZrnyBARUewJelmZmTNnYubMmYO+LkkSnE4nnE6nlnoREcUVji6jmKIeWj3YLaKjPWSTBta3DyZcqw3Esnj4fcqyxnSZEfpkiIhIH0ZtyfB+MkREpBu2ZAxqsBSZGhfOjA3qFNmSdcuV8ouLn49Gdfrh7yVMNI4u03TrZh0xyBARCcCo82SYLiMiIt2wJRNmRkgdqOtthOu5nFi7PnWKTJRRZ7HwucUCTsYkIiLdGDXIMF1GRES6YUsmzIyWOjDa9fQVy9cn+qgzCo5R58kwyBARCUD2aUt5yb4wViaMmC4jIiLdMMgQGcCLi59XHjPn3Kc84tUIy3eUR6zoTZdpeQRr165duOeee5CWlgZJkvDHP/7R73VZluF0OpGWloakpCTk5+fjyJEjQZ2DQYaISACyLGt+BOv8+fO4+eabsX79+gFfX7t2LSoqKrB+/Xo0NTXBbrejoKAAHR0dAZ+DfTJERHGqqKgIRUVFA74myzIqKyuxatUqzJ49GwBQU1MDm82G2tpaFBcXB3QOBhkDCWR5fzK+t+u2KOUZMwqU8nvvNQR9rFibrNorlurayydrHF32bUvG6/X6bTebzTCbzUEfr6WlBR6PB4WFhX7HysvLw969ewMOMkyXEREJoHcyppYHAKSnp8NqtSoPt9sdUn08Hg8AwGaz+W232WzKa4FgS4aISADhmifT2tqK5ORkZXsorRg1SZL8nsuy3G/b5TDIGAhTZNSXOkX2H5/VKOUfj1sQ0P6ip51iNZ2np+TkZL8gEyq73Q7gYosmNTVV2d7W1tavdXM5TJcREQkgXOmycMnIyIDdbkdDw6X/qHR1daGxsRG5ubkBH4ctGSIiAURjgcxz587h008/VZ63tLTg4MGDGDlyJMaMGYOysjK4XC5kZmYiMzMTLpcLw4YNw7x58wI+B4MMUZxQp8gec5Yq5Y3Ol6NRnbBgikybAwcOYMaMGcpzh8MBAFiwYAE2b96MpUuX4sKFCygpKcHZs2eRk5OD+vp6WCyWgM/BIENEJABZY8d/KC2Z/Pz8y07ilCQJTqcTTqcz5HoxyBARCSDUWfvq/UXEIBMDOIKGwk2dIqt4+0Wl7Ji5JKL16Lu2GH/fxsMgQ0QkAN5PhoiIdGPU2y8zyMQAphBIT+oUWd/bA6jXQdMDf9vGxyBDRCQApsuIiEg3sqwxXSbo6DIuK0NERLphS4bCjkOuY9fHf/3Q7/mruy/dMbH4tkWRrk5c8fl88Pl8mvYXEYMMEZEA2CdDRES64RBmogDFUoqMqT1/fe9JpE6RqVcGqH3q/ynlA0f3618xilkMMkREAriYLtPSJ8OWDBERDULukSH3aEiXadhXT4YIMlxkj0h/6pUB1KmzAzOZLqPBGSLIEBHFOlnjEGaZQ5iJiGgwHMIsMKbHKFT87YRGnTp79je/VMrPzH86GtUhgRkiyBARxTqjrl3GIENEJAAuK0MUIE5wjC87/+8upZw94ValzEmaBDDIEBEJgcvKEBGRbpguIwoQU2Tx5b33GgbcvmTdcqX8x/I/KOW+66ORsTHIEBEJgPNkiIhIN+yTISIKwouLn1fKjzlLlfKnTqbLBmLUPhlTtCtARETGFVSQ6e7uxs9//nNkZGQgKSkJ48aNw+rVq/0iqCzLcDqdSEtLQ1JSEvLz83HkyJGwV5yIyEh6+2S0PEQUVLqsvLwcr7zyCmpqajBx4kQcOHAAjzzyCKxWK5544gkAwNq1a1FRUYHNmzfjuuuuw3PPPYeCggIcO3YMFotFl4ug6DDapEujXY9INjpfVspc62xgF/tktKzCbIAg85//+Z+49957cffddwMAvvvd7+L111/HgQMHAFxsxVRWVmLVqlWYPXs2AKCmpgY2mw21tbUoLi7ud8zOzk50dnYqz71eb8gXQ0REYgkqXTZ9+nT85S9/wfHjxwEAf/vb37Bnzx7cddddAICWlhZ4PB4UFhYq+5jNZuTl5WHv3r0DHtPtdsNqtSqP9PT0UK+FiChm+WSN6TIjLJC5bNkytLe3Y/z48UhISEBPTw/WrFmDuXPnAgA8Hg8AwGaz+e1ns9lw4sSJAY+5YsUKOBwO5bnX62WgiRFGSykZ7XpE9W8lFUr51d3r/V4rvm2RUtY7fXnt6Ey/51GfJNrjg9yjYYSYln11FFSQqaurw29/+1vU1tZi4sSJOHjwIMrKypCWloYFCxYo75MkyW8/WZb7betlNpthNptDqDoREYkuqCDz1FNPYfny5fjJT34CALjxxhtx4sQJuN1uLFiwAHa7HcDFFk1qaqqyX1tbW7/WDRERXWLUGf9B9cl89dVXMJn8d0lISFCGMGdkZMBut6Oh4dJaRl1dXWhsbERubm4YqktEZEwcwgzgnnvuwZo1azBmzBhMnDgRH3zwASoqKvDoo48CuJgmKysrg8vlQmZmJjIzM+FyuTBs2DDMmzcvqIpZh4/AVdIQv20i5szVeWNAzDoSiUT9d0TdBwMAM+fcp5Tfrtuiaz2i3gcTJ4IKMuvWrcPTTz+NkpIStLW1IS0tDcXFxfjFL36hvGfp0qW4cOECSkpKcPbsWeTk5KC+vp5zZIiILkP2+TTOkzFAx7/FYkFlZSUqKysHfY8kSXA6nXA6nRqrRkQUP4zaJyPsApnt575EIq6KdjWuiOmx0Igyuz7QeohS31gV6OenTpFFMnUmAqO2ZLhAJhER6UbYlgwRUTxhukwATFkYhyjfnyj1MLpQPmd1iiweFtWUfdpm/DNdRkREcSemWjJEREbFdJkAmNqgcAs0BcvfXviEkvZWp8iWrFuulNW3eNbr3JEia1wgU9PimjpiuoyIiHQTUy0ZIiKjkntkyD2hp7y07KsnBhmKCvW9PKK5hpRoKZN4oPUzV6fI5pYtVMqvV27W/dx68vXI8GlIefkEDTJMlxERkW7YkiEiEoFPhqxlhBhHlxFdcrr9dLSrQAbwzq/fUsoVb7+olB0zl0SjOpr4enwa02XB7et0OvHss8/6bbPZbPB4PCHXYSAMMkREcWrixIn485//rDxPSEgI+zkYZIiIBBCNZWUSExNht9tDPmdA59D16BRRIk8060v0+lFsUP+O1CmyV3evV8p9774pKrlHhmzSPoTZ6/X6bTebzTCbzQPu88knnyAtLQ1msxk5OTlwuVwYN25cyHUYCEeXEREJwOfzaX4AQHp6OqxWq/Jwu90Dni8nJwevvfYa3n33XWzcuBEejwe5ubk4c+ZMWK+LLRkiIgNpbW1FcnKy8nywVkxRUZFSvvHGGzF16lR873vfQ01NDRwOR9jqwyBjIExBEV2kTpFpWessksKVLktOTvYLMoG6+uqrceONN+KTT8I7OZrpMiIiAfQukKnloUVnZyeOHj2K1NTUMF3RRQwyRERxaMmSJWhsbERLSwv+67/+Cz/+8Y/h9XqxYMGCsJ6H6TIylFgaYRfLwvU5q4+j9ViDUafIsifcqpQPHN0/aF2i8dvx9cjwaUiXBbt22T//+U/MnTsXp0+fxr/8y7/gX//1X7Fv3z6MHTs25DoMhEGGiEgAss+n6RbKwe77xhtvhHyuYDBdRkREuhG+JRPtJqzeYvn6RKy7KPUwOi2fs/o2D5Few05db3XqDOifPos0n0/j2mUaWkF6Ej7IEBHFA7lHhiwZ76ZlTJcREZFu2JIhIhLAxZaMho5/QVsywgeZQHK/kRgGqZdYqmtfsVx3ip5I3G57sP7Cy5175pz7lPLbdVv0qdhl+HwyfBpuPKZlXz0xXUZERLoRviVDRBQXenya0mXQuKyMXgwRZJi2MQ4Rh0VT7Anlt/PxXz9Uyq9/+GulPDfrp2Gp05UYdXSZIYIMEVGsM+o8GfbJEBGRbtiSIaEwRUbRoh55pk6RRepWzrJPW5+MlnXP9MQgQ0QkAF+PDB8itwpzpDBdRkREumFLJg5wxFb8Mvp3H4nrU6fIehfV7Oz5GnuO14f1PHKPDzK0zPhnuoyIiAYh98iQNaTLOIQ5QLJ88YPqRneUa2Ic38hdSrkb30SxJhRpRv/uI319nT1fAwC6ejoBXPr3igYnXJDp6OgAAOzDjijXxEDORbsCFDVG/+4jfH19U2QdHR2wWq1hObbP54NPw+gyUefJCBdk0tLS0NraClmWMWbMGLS2tiI5OTna1YoYr9eL9PR0Xnec4HXH5nXLsoyOjg6kpaWF7Zg+2QefrCHIaNhXT8IFGZPJhNGjR8Pr9QIAkpOTY/JHqBWvO77wumNPuFowRidckCEiikc+n6wxXSZm/xCDDBGRAHxyD3y+Hk37i0jYyZhmsxnPPPMMzGZztKsSUbxuXnc8iNfrjkeSzDF4RERR4/V6YbVa8b8zHBhiCj3odvk6Ud1Sgfb2dqH6uZguIyISgM/ng0/DjH8OYSYiokEZNcgI2ydDRESxjy0ZIiIBcDImERHpxufrgQ8ahjBrGP6sJ6bLiIhIN2zJEBEJwKgd/wwyREQC8Mmyxj4ZMac8Ml1GRES6YUuGiEgATJcREZFujBpkmC4jIiLdsCVDRCQAn9yDHg3L9Yu61D+DDBGRAHyyT1PKS9QZ/0yXERGRbtiSISISgM/n03b7ZUFbMgwyREQC8MkaR5cxyBAR0WCM2pJhnwwREemGLRkiIgFcTJdpGcIsZkuGQYaISABMlxEREQWJLRkiIgEYtSXDIENEJACf7EOPAYcwM11GRES6YUuGiEgATJcREZFufL4e+KTQk0uirsLMdBkRURzbsGEDMjIyMHToUEyePBm7d+8O6/EZZIiIBOCTfZofwaqrq0NZWRlWrVqFDz74ALfddhuKiopw8uTJsF2XJMuyHLajERFRULxeL6xWK6ajEIm4KuTjdOMb7EE92tvbkZycHNA+OTk5+P73v4+qqipl24QJEzBr1iy43e6Q66LGPhkiIgF0ozss+3u9Xr/tZrMZZrO53/u7urrQ3NyM5cuX+20vLCzE3r17NdVFjUGGiCiKhgwZArvdjn2eHZqPNXz4cKSnp/tte+aZZ+B0Ovu99/Tp0+jp6YHNZvPbbrPZ4PF4NNelF4MMEVEUDR06FC0tLejq6tJ8LFmWIUmS37aBWjFqfd8/0DG0YJAhIoqyoUOHYujQoRE956hRo5CQkNCv1dLW1tavdaMFR5cREcWhIUOGYPLkyWhoaPDb3tDQgNzc3LCdhy0ZIqI45XA4MH/+fGRnZ2Pq1Kmorq7GyZMn8fjjj4ftHAwyRERxas6cOThz5gxWr16NU6dOISsrC9u2bcPYsWPDdg7OkyEiIt2wT4aIiHTDIENERLphkCEiIt0wyBARkW4YZIiISDcMMkREpBsGGSIi0g2DDBER6YZBhoiIdMMgQ0REumGQISIi3fx/VJOBZiaKLA0AAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"# data augmentation \n\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.72))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(96, activation='softmax'))\n\n# Create an instance of the ImageDataGenerator for data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,      # Randomly rotate the images by up to 20 degrees\n    width_shift_range=0.1,  # Randomly shift the width of the images by up to 10%\n    height_shift_range=0.1, # Randomly shift the height of the images by up to 10%\n    zoom_range=0.2,         # Randomly zoom in/out on the images by up to 20%\n    horizontal_flip=True,   # Randomly flip the images horizontally\n    fill_mode='nearest'     # Fill any newly created pixels after rotation or shifting\n)\n\n# Apply data augmentation to the training dataset\ntrain_generator = datagen.flow(trainImages, trainLabels, batch_size=64)\n\n\n\n\n# model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \n\nlr_scheduler = ReduceLROnPlateau(factor=0.1, patience=3)\n# model.fit(trainImages, trainLabels, batch_size=64, epochs=120, verbose=1, callbacks=[lr_scheduler])\n\n# validate(model, validationImages, validationLabels)\n\n# Compile the model with the optimizer and loss function\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n\n# Fit the model using the augmented data generator\nmodel.fit(train_generator, epochs=40, verbose=1,callbacks=[lr_scheduler])\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:29:16.727018Z","iopub.status.idle":"2023-06-20T16:29:16.727633Z","shell.execute_reply.started":"2023-06-20T16:29:16.727401Z","shell.execute_reply":"2023-06-20T16:29:16.727422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data augmentation \n# 120 epoch\n# 20 epoch = 63\n# 20 epoch no scheduler 64 i gues??\n\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.72))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(96, activation='softmax'))\n\n# Create an instance of the ImageDataGenerator for data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,      # Randomly rotate the images by up to 20 degrees\n#     width_shift_range=0.05,  # Randomly shift the width of the images by up to 10%\n#     height_shift_range=0.05, # Randomly shift the height of the images by up to 10%\n    zoom_range=0.2,         # Randomly zoom in/out on the images by up to 20%\n    horizontal_flip=True,   # Randomly flip the images horizontally\n    fill_mode='nearest'     # Fill any newly created pixels after rotation or shifting\n)\n\n# Apply data augmentation to the training dataset\ntrain_generator = datagen.flow(trainImages, trainLabels, batch_size=64)\n\n\n\n\n# model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \n\nlr_scheduler = ReduceLROnPlateau(factor=0.1, patience=3)\n# model.fit(trainImages, trainLabels, batch_size=64, epochs=120, verbose=1, callbacks=[lr_scheduler])\n\n# validate(model, validationImages, validationLabels)\n\n# Compile the model with the optimizer and loss function\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n\n# Fit the model using the augmented data generator\nmodel.fit(train_generator, epochs=20, verbose=1)\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:29:16.729039Z","iopub.status.idle":"2023-06-20T16:29:16.729940Z","shell.execute_reply.started":"2023-06-20T16:29:16.729704Z","shell.execute_reply":"2023-06-20T16:29:16.729727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit with n\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.72))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(96, activation='softmax'))\n\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \n\nlr_scheduler = ReduceLROnPlateau(factor=0.1, patience=3)\nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=120, verbose=1, callbacks=[lr_scheduler])\n\nvalidate(model, validationImages, validationLabels)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T18:32:06.695564Z","iopub.execute_input":"2023-06-20T18:32:06.696254Z","iopub.status.idle":"2023-06-20T18:37:34.283360Z","shell.execute_reply.started":"2023-06-20T18:32:06.696221Z","shell.execute_reply":"2023-06-20T18:37:34.281894Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/120\n","output_type":"stream"},{"name":"stderr","text":"2023-06-20 18:32:12.185544: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"188/188 [==============================] - 12s 14ms/step - loss: 4.3568 - accuracy: 0.0733 - lr: 0.0010\nEpoch 2/120\n188/188 [==============================] - 2s 13ms/step - loss: 3.3385 - accuracy: 0.2097 - lr: 0.0010\nEpoch 3/120\n188/188 [==============================] - 2s 13ms/step - loss: 2.6053 - accuracy: 0.3262 - lr: 0.0010\nEpoch 4/120\n188/188 [==============================] - 3s 14ms/step - loss: 2.1525 - accuracy: 0.4149 - lr: 0.0010\nEpoch 5/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.9091 - accuracy: 0.4659 - lr: 0.0010\nEpoch 6/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.6821 - accuracy: 0.5134 - lr: 0.0010\nEpoch 7/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.5509 - accuracy: 0.5497 - lr: 0.0010\nEpoch 8/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.4293 - accuracy: 0.5738 - lr: 0.0010\nEpoch 9/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.3573 - accuracy: 0.5941 - lr: 0.0010\nEpoch 10/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.2909 - accuracy: 0.6106 - lr: 0.0010\nEpoch 11/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.1532 - accuracy: 0.6472 - lr: 0.0010\nEpoch 12/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.1072 - accuracy: 0.6574 - lr: 0.0010\nEpoch 13/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.0506 - accuracy: 0.6713 - lr: 0.0010\nEpoch 14/120\n188/188 [==============================] - 2s 13ms/step - loss: 1.0077 - accuracy: 0.6848 - lr: 0.0010\nEpoch 15/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.9593 - accuracy: 0.6988 - lr: 0.0010\nEpoch 16/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.9229 - accuracy: 0.7064 - lr: 0.0010\nEpoch 17/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.8892 - accuracy: 0.7229 - lr: 0.0010\nEpoch 18/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.8627 - accuracy: 0.7267 - lr: 0.0010\nEpoch 19/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.8367 - accuracy: 0.7302 - lr: 0.0010\nEpoch 20/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.7863 - accuracy: 0.7499 - lr: 0.0010\nEpoch 21/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.7784 - accuracy: 0.7521 - lr: 0.0010\nEpoch 22/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.7287 - accuracy: 0.7641 - lr: 0.0010\nEpoch 23/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.7105 - accuracy: 0.7697 - lr: 0.0010\nEpoch 24/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.7178 - accuracy: 0.7655 - lr: 0.0010\nEpoch 25/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.6834 - accuracy: 0.7763 - lr: 0.0010\nEpoch 26/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.6455 - accuracy: 0.7915 - lr: 0.0010\nEpoch 27/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.6370 - accuracy: 0.7927 - lr: 0.0010\nEpoch 28/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.6477 - accuracy: 0.7933 - lr: 0.0010\nEpoch 29/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.6013 - accuracy: 0.8039 - lr: 0.0010\nEpoch 30/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.5948 - accuracy: 0.8059 - lr: 0.0010\nEpoch 31/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.5855 - accuracy: 0.8104 - lr: 0.0010\nEpoch 32/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.5763 - accuracy: 0.8092 - lr: 0.0010\nEpoch 33/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.5421 - accuracy: 0.8207 - lr: 0.0010\nEpoch 34/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.5365 - accuracy: 0.8219 - lr: 0.0010\nEpoch 35/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.5353 - accuracy: 0.8248 - lr: 0.0010\nEpoch 36/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.5195 - accuracy: 0.8294 - lr: 0.0010\nEpoch 37/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4989 - accuracy: 0.8338 - lr: 0.0010\nEpoch 38/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4816 - accuracy: 0.8387 - lr: 0.0010\nEpoch 39/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4914 - accuracy: 0.8348 - lr: 0.0010\nEpoch 40/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4765 - accuracy: 0.8440 - lr: 0.0010\nEpoch 41/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4695 - accuracy: 0.8441 - lr: 0.0010\nEpoch 42/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.4819 - accuracy: 0.8436 - lr: 0.0010\nEpoch 43/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4554 - accuracy: 0.8524 - lr: 0.0010\nEpoch 44/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4359 - accuracy: 0.8573 - lr: 0.0010\nEpoch 45/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4493 - accuracy: 0.8508 - lr: 0.0010\nEpoch 46/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4153 - accuracy: 0.8648 - lr: 0.0010\nEpoch 47/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.4209 - accuracy: 0.8578 - lr: 0.0010\nEpoch 48/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4073 - accuracy: 0.8649 - lr: 0.0010\nEpoch 49/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4149 - accuracy: 0.8622 - lr: 0.0010\nEpoch 50/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4140 - accuracy: 0.8643 - lr: 0.0010\nEpoch 51/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3894 - accuracy: 0.8698 - lr: 0.0010\nEpoch 52/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4138 - accuracy: 0.8662 - lr: 0.0010\nEpoch 53/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.4007 - accuracy: 0.8641 - lr: 0.0010\nEpoch 54/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3758 - accuracy: 0.8746 - lr: 0.0010\nEpoch 55/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.3833 - accuracy: 0.8717 - lr: 0.0010\nEpoch 56/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3803 - accuracy: 0.8755 - lr: 0.0010\nEpoch 57/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3735 - accuracy: 0.8751 - lr: 0.0010\nEpoch 58/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3547 - accuracy: 0.8788 - lr: 0.0010\nEpoch 59/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3485 - accuracy: 0.8857 - lr: 0.0010\nEpoch 60/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3550 - accuracy: 0.8814 - lr: 0.0010\nEpoch 61/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3408 - accuracy: 0.8839 - lr: 0.0010\nEpoch 62/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3574 - accuracy: 0.8813 - lr: 0.0010\nEpoch 63/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3571 - accuracy: 0.8797 - lr: 0.0010\nEpoch 64/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3373 - accuracy: 0.8886 - lr: 0.0010\nEpoch 65/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3224 - accuracy: 0.8943 - lr: 0.0010\nEpoch 66/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3241 - accuracy: 0.8925 - lr: 0.0010\nEpoch 67/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3312 - accuracy: 0.8914 - lr: 0.0010\nEpoch 68/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.3045 - accuracy: 0.8984 - lr: 0.0010\nEpoch 69/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3307 - accuracy: 0.8917 - lr: 0.0010\nEpoch 70/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2997 - accuracy: 0.8976 - lr: 0.0010\nEpoch 71/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2893 - accuracy: 0.9044 - lr: 0.0010\nEpoch 72/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.3048 - accuracy: 0.8959 - lr: 0.0010\nEpoch 73/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2918 - accuracy: 0.9035 - lr: 0.0010\nEpoch 74/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2882 - accuracy: 0.9036 - lr: 0.0010\nEpoch 75/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.3093 - accuracy: 0.8957 - lr: 0.0010\nEpoch 76/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2900 - accuracy: 0.9032 - lr: 0.0010\nEpoch 77/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2951 - accuracy: 0.9018 - lr: 0.0010\nEpoch 78/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2755 - accuracy: 0.9078 - lr: 0.0010\nEpoch 79/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2793 - accuracy: 0.9063 - lr: 0.0010\nEpoch 80/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2677 - accuracy: 0.9105 - lr: 0.0010\nEpoch 81/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2695 - accuracy: 0.9086 - lr: 0.0010\nEpoch 82/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2647 - accuracy: 0.9107 - lr: 0.0010\nEpoch 83/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2679 - accuracy: 0.9118 - lr: 0.0010\nEpoch 84/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2806 - accuracy: 0.9053 - lr: 0.0010\nEpoch 85/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2718 - accuracy: 0.9109 - lr: 0.0010\nEpoch 86/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2541 - accuracy: 0.9132 - lr: 0.0010\nEpoch 87/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2515 - accuracy: 0.9124 - lr: 0.0010\nEpoch 88/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2646 - accuracy: 0.9131 - lr: 0.0010\nEpoch 89/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2683 - accuracy: 0.9102 - lr: 0.0010\nEpoch 90/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2488 - accuracy: 0.9162 - lr: 0.0010\nEpoch 91/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2594 - accuracy: 0.9125 - lr: 0.0010\nEpoch 92/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2652 - accuracy: 0.9121 - lr: 0.0010\nEpoch 93/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2498 - accuracy: 0.9154 - lr: 0.0010\nEpoch 94/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2475 - accuracy: 0.9158 - lr: 0.0010\nEpoch 95/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2466 - accuracy: 0.9197 - lr: 0.0010\nEpoch 96/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2425 - accuracy: 0.9172 - lr: 0.0010\nEpoch 97/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2362 - accuracy: 0.9219 - lr: 0.0010\nEpoch 98/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2366 - accuracy: 0.9193 - lr: 0.0010\nEpoch 99/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2390 - accuracy: 0.9187 - lr: 0.0010\nEpoch 100/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2410 - accuracy: 0.9184 - lr: 0.0010\nEpoch 101/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2205 - accuracy: 0.9250 - lr: 0.0010\nEpoch 102/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2213 - accuracy: 0.9264 - lr: 0.0010\nEpoch 103/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2277 - accuracy: 0.9238 - lr: 0.0010\nEpoch 104/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2213 - accuracy: 0.9245 - lr: 0.0010\nEpoch 105/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2152 - accuracy: 0.9279 - lr: 0.0010\nEpoch 106/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2187 - accuracy: 0.9257 - lr: 0.0010\nEpoch 107/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2141 - accuracy: 0.9266 - lr: 0.0010\nEpoch 108/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2212 - accuracy: 0.9264 - lr: 0.0010\nEpoch 109/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2328 - accuracy: 0.9211 - lr: 0.0010\nEpoch 110/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2186 - accuracy: 0.9244 - lr: 0.0010\nEpoch 111/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2197 - accuracy: 0.9253 - lr: 0.0010\nEpoch 112/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2135 - accuracy: 0.9302 - lr: 0.0010\nEpoch 113/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2035 - accuracy: 0.9308 - lr: 0.0010\nEpoch 114/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2211 - accuracy: 0.9233 - lr: 0.0010\nEpoch 115/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.1981 - accuracy: 0.9350 - lr: 0.0010\nEpoch 116/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2088 - accuracy: 0.9320 - lr: 0.0010\nEpoch 117/120\n188/188 [==============================] - 2s 13ms/step - loss: 0.2071 - accuracy: 0.9331 - lr: 0.0010\nEpoch 118/120\n188/188 [==============================] - 3s 14ms/step - loss: 0.2005 - accuracy: 0.9341 - lr: 0.0010\nEpoch 119/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2162 - accuracy: 0.9283 - lr: 0.0010\nEpoch 120/120\n188/188 [==============================] - 3s 13ms/step - loss: 0.2080 - accuracy: 0.9320 - lr: 0.0010\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(trainImages, trainLabels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[lr_scheduler])\n\u001b[0;32m---> 25\u001b[0m \u001b[43mvalidate\u001b[49m(model, validationImages, validationLabels)\n","\u001b[0;31mNameError\u001b[0m: name 'validate' is not defined"],"ename":"NameError","evalue":"name 'validate' is not defined","output_type":"error"}]},{"cell_type":"code","source":"\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='gelu', input_shape=(64, 64, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))#relu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='gelu')) #gelu\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.72))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(96, activation='softmax'))\n\n\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy']) \n\nlr_scheduler = ReduceLROnPlateau(factor=0.1, patience=3)\nmodel.fit(trainImages, trainLabels, batch_size=64, epochs=20, verbose=1, callbacks=[lr_scheduler])\n\nvalidate(model, validationImages, validationLabels)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:29:16.734500Z","iopub.status.idle":"2023-06-20T16:29:16.734955Z","shell.execute_reply.started":"2023-06-20T16:29:16.734716Z","shell.execute_reply":"2023-06-20T16:29:16.734737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.naive_bayes import MultinomialNB\nfrom PIL import Image # Pentru porcesari de imagine\nfrom PIL import ImageFilter # Pentru adaugarea de noise peste datele de train -> mai multe date de antrenare\nimport matplotlib.pyplot as plt # Pentru afisarea matricii de confuzie\nimport time\n\n\n\n# train\ntrainImages = []\ntrainLabels = []\n\nreadFile = open(\"/kaggle/input/unibuc-dhc-2023/train.csv\",'r')\npair = readFile.readline() #trecem peste prima linie\npair = readFile.readline()\nwhile pair:\n    pair = pair.split(\",\")\n    image = Image.open(\"/kaggle/input/unibuc-dhc-2023/train_images/\" + pair[0])\n    imageArray = np.asarray(image).flatten() \n    image.close()\n    trainImages.append(imageArray) \n    trainLabels.append(int(pair[1]))\n    pair = readFile.readline()\n        \n        \n# validation\nvalidationImages = []\nvalidationLabels = []\n\nreadFile = open(\"/kaggle/input/unibuc-dhc-2023/val.csv\",'r')\npair = readFile.readline() #trecem peste prima linie\npair = readFile.readline()\nwhile pair:\n    pair = pair.split(\",\")\n    image = Image.open(\"/kaggle/input/unibuc-dhc-2023/val_images/\" + pair[0])\n    imageArray = np.asarray(image).flatten() \n    image.close()\n    validationImages.append(imageArray) \n    validationLabels.append(int(pair[1]))\n    pair = readFile.readline()\n        \n\n        \n# test\n\n\ntestImages = []\ntestImageNames = []\n        \nreadFile = open(\"/kaggle/input/unibuc-dhc-2023/test.csv\",'r')\npair = readFile.readline() #trecem peste prima linie\npair = readFile.readline()\nwhile pair:\n    pair = pair.rstrip(\"\\n\")\n    image = Image.open(\"/kaggle/input/unibuc-dhc-2023/test_images/\" + pair)\n    imageArray = np.asarray(image).flatten()  \n    image.close()\n    testImageNames.append(pair)\n    testImages.append(imageArray) \n    pair = readFile.readline()\n    \n\n# arr = np.array(trainImages)\n# print(arr.shape)\n# print(\"test\")\n# print(testImageNames[2])\n\n        \n        \ntrainImages = np.stack(trainImages, axis=0)\nvalidationImages = np.stack(validationImages, axis=0)\ntrainLabels = np.stack(trainLabels, axis=0)\nvalidationLabels = np.stack(validationLabels, axis=0)\n\ntrainImages = trainImages/255\nvalidationImages = validationImages/255\n        \n        \ntestImages = np.stack(testImages, axis=0)\ntestImages = testImages/255\n\nmegaTrain = np.concatenate((trainImages, validationImages),axis=0)\nmegaTrainLabels = np.concatenate((trainLabels, validationLabels),axis=0)\n\n\nmodel = MultinomialNB()\n# antrenarea modelului\nstart = time.process_time()\nmodel.fit(trainImages, trainLabels)\nprint(\"Time taken: \" + str(time.process_time() - start))\n\n\npredicted = model.predict(validationImages)\n\nprint(model.score(validationImages, validationLabels))\n\n\n\n\nmodel = MultinomialNB()\n# antrenarea modelului\nstart = time.process_time()\nmodel.fit(megaTrain, megaTrainLabels)\nprint(\"Time taken: \" + str(time.process_time() - start))\n\npredicted = model.predict(testImages)\nf = open(\"submissionNB.csv\", \"w\")\nf.write(\"Image,Class\\n\")\nfor i in range(len(testImages)):\n    string = str(testImageNames[i]).rstrip('\\n') + \",\" + str(predicted[i]).rstrip('\\n') + \"\\n\"\n    f.write(string)\nf.close()\n\n\nmodel.fit(trainImages, trainLabels)\npredicted = model.predict(validationImages)\n\nconfusionMatrix = np.zeros((96, 96))\nfor i in range(len(validationImages)):\n    confusionMatrix[validationLabels[i], predicted[i]] += 1\n    \nplt.figure(figsize=(10,10))\nplt.matshow(confusionMatrix,cmap='PRGn')\nplt.colorbar()\nplt.show()\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T16:29:16.736810Z","iopub.status.idle":"2023-06-20T16:29:16.737279Z","shell.execute_reply.started":"2023-06-20T16:29:16.737034Z","shell.execute_reply":"2023-06-20T16:29:16.737055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(testImages.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T18:16:56.943603Z","iopub.execute_input":"2023-06-20T18:16:56.944035Z","iopub.status.idle":"2023-06-20T18:16:56.950074Z","shell.execute_reply.started":"2023-06-20T18:16:56.944002Z","shell.execute_reply":"2023-06-20T18:16:56.949016Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(5000, 64, 64, 3)\n","output_type":"stream"}]}]}