{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpoTZudv_LK5"
      },
      "source": [
        "## Straturi Noi\n",
        "\n",
        "In continuare o sa utilizam o parte din straturile prezentate in curs.\n",
        "\n",
        "Staturi noi:\n",
        "\n",
        "Layer Convolutional:\n",
        "* [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
        "\n",
        "Layere Pooling:\n",
        "* [torch.nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)(kernel_size, stride=None, padding=0)\n",
        "*  [torch.nn.AveragePool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html)(kernel_size, stride=None, padding=0)\n",
        "\n",
        "Layere Adaptive Pool, intalnit adesea si ca Global Pool:\n",
        "* [torch.nn.AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)(output_size)\n",
        "* [torch.nn.AdaptiveMaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html)(output_size)\n",
        "\n",
        "Layer de liniarizare:\n",
        "\n",
        "* [torch.nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.flatten.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muaF8nG2CNdm"
      },
      "source": [
        "Four **hyperparameters** control the size of the output volume:\n",
        "* **Depth**: number of filters, as each filter _looks_ at different areas of the input:\n",
        "* **Stride**: the step taken when _sliding_ the filter. (Usually 1 or 2, 3 - uncommon).\n",
        "* **Zero-Padding**: size of the number of 0s that surround the border of the input volume. Example: If you want to the same width and height for input and output.\n",
        "* **Dilation**: Distance between elements of the convolutional kernel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJUUhdghGKMF"
      },
      "source": [
        "**Why Pooling Layer?**\n",
        "\n",
        "1. Modifica volumul de input (input volume) in reprezentari _mai mici_ si mai usor de _manevrat_.\n",
        "2. Opereaza independent pe fiecare Activation Map.\n",
        "\n",
        "<img src=\"https://computersciencewiki.org/images/9/9e/MaxpoolSample.png\" width=\"425\" height=\"300\"/> <img src=\"https://miro.medium.com/v2/resize:fit:517/0*lIcR0gOMK0xzTr6_.png\" width=\"425\" height=\"300\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1xV1DWySMUk"
      },
      "source": [
        "**Why Adaptive Pooling Layer?**\n",
        "\n",
        "1. Folosite de regula in etapele finale de constructie a unei arhitecturi de tipul _ConvNet_ pentru a inlocui fully-connected layers.\n",
        "2. Incearca sa previna *overfitting phenomenon* fortand feature maps sa retina informatia **globala** care este relevanta pentru task-ul acestei _ConvNet_ (clasificare, identifcare etc.)\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/338079465/figure/fig4/AS:905983672987648@1593014748012/The-difference-of-max-pooling-and-global-max-pooling.ppm\" width=\"725\" height=\"300\"/>\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=11l7Xsh-iQmASvXTkgH2MgtA01XCW6CAC\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoaES2H0SK6f"
      },
      "source": [
        "[Visualise them Here](https://github.com/vdumoulin/conv_arithmetic)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5HWqK9mqHxgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316f33e9-12b0-4100-df40-f793ec38637d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1 result shape torch.Size([1, 10, 49, 49])\n",
            "Conv2 result shape torch.Size([1, 10, 44, 44])\n",
            "Pool result shape torch.Size([1, 3, 33, 33])\n",
            "Global Pool result shape torch.Size([1, 3, 5, 5])\n",
            "Flaten result shape torch.Size([1, 30000])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n",
        "print(\"Conv1 result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(13,13), stride=(2,2))\n",
        "print(\"Conv2 result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.MaxPool2d(kernel_size=(3,3)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n",
        "print(\"Pool result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "# Utilizate pentru a reduce dimensiunea la una prestabilita, util cand marimea input ului este variabil\n",
        "layer = nn.AdaptiveAvgPool2d(output_size=(5,5))\n",
        "print(\"Global Pool result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.Flatten()\n",
        "print(\"Flaten result shape\",layer(dummy_input_tensor).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOTmqyCxJ3fk"
      },
      "source": [
        "### Cerinte\n",
        "\n",
        "**(1p)** Utilizati o serie de Conv2D/Pool2D pentru a ajunge la urmatoarele marimi plecand de la input 3x100x100:\n",
        "*   [1, 10, 25, 25] # Stride & Padding\n",
        "*   [1, 10, 32, 32]\n",
        "*  [1, 3, 2, 2]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7HtEeXbeKeKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b587a1a-02af-408d-d338-d62f8e535871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cerinta 1:  torch.Size([1, 10, 25, 25])\n",
            "Cerinta 2:  torch.Size([1, 10, 32, 32])\n",
            "Cerinta 2:  torch.Size([1, 3, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
        "\n",
        "\n",
        "\n",
        "# Cerinta 1: [1, 10,25, 25]\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(5,5), stride=(4,4), padding=1)\n",
        "print(\"Cerinta 1: \",layer(dummy_input_tensor).shape)\n",
        "\n",
        "\n",
        "# Cerinta 2: [1, 10, 32, 32]\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(5,5), stride=(3,3), padding=0)\n",
        "print(\"Cerinta 2: \",layer(dummy_input_tensor).shape)\n",
        "\n",
        "\n",
        "# Cerinta 3: [1, 3, 2, 2]\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(20,20), stride=(4,4), padding=0)\n",
        "layer2 = nn.MaxPool2d(kernel_size=(10,10))\n",
        "\n",
        "print(\"Cerinta 2: \",layer2(layer(dummy_input_tensor)).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvdPtetggm61"
      },
      "source": [
        "## Instantierea seturilor de date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "czyIhYt5gmUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb8a064-a4d9-42e9-d3c4-e1d96cbaab1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:11<00:00, 15358236.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "\n",
        "cifar_train = torchvision.datasets.CIFAR10(\"./data\", download=True)\n",
        "cifar_test = torchvision.datasets.CIFAR10(\"./data\", train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOA4ted_hHdB"
      },
      "source": [
        "## Crearea Dataloader-ului\n",
        "\n",
        "### Cerinte\n",
        " * **(2p)** Implementati functia de preprocesare a datelor, __collate_fn(examples)__.\n",
        "\n",
        "\n",
        "Atentie! Spre deosebire de intrarea pentru retelele fully-connected, pentru retelele convolutionale intrearea nu trebuie liniarizata, ci doar normalizata.\n",
        "\n",
        "#### Hint\n",
        "\n",
        "  * Amintiti-va folosirea functiei __normalize__ din torchvision.transforms.functional din laboratorul trecut.\n",
        "  * Modificati functia *collate_fn* din laboratorul trecut, pentru a normaliza datele in intervalul [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf4CRtpGHz2o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "def collate_fn(examples):\n",
        "  ### Completati codul pentru cerinta aici\n",
        "\n",
        "  processed_images = []\n",
        "  processed_labels = []\n",
        "\n",
        "  for example in examples: # example este un tuplu returnat de obiectul de tip Dataset\n",
        "    pil_image = example[0]\n",
        "    tensor_image = to_tensor(pil_image)\n",
        "\n",
        "    tensor_image = normalize(tensor_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    # tensor_image = tensor_image.unsqueeze(0) # Adauga inca o dimensiune la inceputul imaginii -> 1 x 32 x 32 x 3\n",
        "    processed_images.append(tensor_image)\n",
        "\n",
        "    label = example[1]\n",
        "\n",
        "    processed_labels.append(label)\n",
        "\n",
        "  torch_images = torch.stack(processed_images)\n",
        "  torch_labels = torch.tensor(processed_labels)\n",
        "\n",
        "\n",
        "  return torch_images, torch_labels\n",
        "\n",
        "\n",
        "train_loader = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnV6PIC1kQMi"
      },
      "source": [
        "## Crearea unei retele neurale convolutionale\n",
        "\n",
        "### Cerinte\n",
        " * **(1p)** Creati o clasa care mosteneste clasa nn.Module. Ea va reprezenta o retea neurala convolutionala pentru clasificare ale celor 10 clase din datasetul CIFAR10.\n",
        "    * Reteaua trebuie sa aiba 2 straturi convolutionale care sa reduca dimensiunea spatiala a imaginii de 2 ori (0.25 p).\n",
        "    * Liniarizati iesirea din cel de-al doilea strat convolutional (0.25 p).\n",
        "    * Adaugat stratul final de tipul `fully-connected` (0.25 p).\n",
        "    * Folositi o functie de activare la alegere (Exemplu [RELU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)) (0.25 p).\n",
        "\n",
        "#### Hint\n",
        "\n",
        "Pentru a liniariza iesirea din cel de-al doilea feature map puteti adopta mai multe strategii:\n",
        "  * Liniarizare prin schimbarea shape-ului la [batch_size, -1]\n",
        "  * Global Max Pooling si apoi liniarizare la [batch_size, -1]\n",
        "  * Average Max Pooling si apoi liniarizare la [batch_size, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u1Ddc7D-lAEN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    ### Completati codul pentru cerinta aici\n",
        "\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.pooling = nn.AvgPool2d(kernel_size=(8, 8))\n",
        "\n",
        "    self.linear = nn.Linear(64, 10)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    ### Completati codul pentru cerinta aici\n",
        "    # Trecerea prin primul strat convolutional si activare ReLU\n",
        "    x = self.relu(self.conv1(x))\n",
        "\n",
        "    # Trecerea prin al doilea strat convolutional si activare ReLU\n",
        "    x = self.relu(self.conv2(x))\n",
        "\n",
        "    # Liniarizare\n",
        "    x = self.pooling(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    # Stratul final fully-connected\n",
        "    x = self.linear(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK0Z9NeYTghv"
      },
      "source": [
        "## Definirea obiectelor folosite in timpul antrenarii\n",
        "\n",
        "### Cerinte **(1p)**\n",
        "  * Numarul de epoci (0.25 p)\n",
        "  * Retea (0.25 p)\n",
        "  * Optimizator (0.25 p)\n",
        "  * Alegeti functia de cost (0.25 p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Az3WKQdpod34"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definiti numarul de epoci\n",
        "epochs = 10\n",
        "\n",
        "# Definiti reteaua\n",
        "network = Net()\n",
        "\n",
        "# Definiti optimizatorul\n",
        "optimizer = optim.SGD(network.parameters(), lr=1e-3)\n",
        "\n",
        "\"\"\"\n",
        "Dupa definirea optimizatorului si dupa fiecare iteratie de antrenare, trebuie\n",
        "apelata functia zero_grad() pentru a seta valoare tuturor gradientilor la zero.\n",
        "\"\"\"\n",
        "# Completati aici codul pentru seta valoare tuturor gradientilor la zero\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Definiti functia cost pentru clasificare Cross-Entropy\n",
        "# https://neptune.ai/blog/pytorch-loss-functions\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnUsWYWodb4"
      },
      "source": [
        "## Definirea functiei de antrenare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlBJUj_7GPjA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K9MTYanoMZ8H"
      },
      "outputs": [],
      "source": [
        "def test_acc(net: nn.Module, test_loader: DataLoader):\n",
        "  net.eval()\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for test_images, test_labels in test_loader:\n",
        "    total += len(test_images)\n",
        "    out_class = torch.argmax(net(test_images))\n",
        "    correct += torch.sum(out_class == test_labels)\n",
        "\n",
        "  return correct / total * 100\n",
        "\n",
        "\n",
        "def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader,\n",
        "             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n",
        "  # Iteram prin numarul de epoci\n",
        "  for e in range(epochs):\n",
        "    net.train()\n",
        "\n",
        "    # Iteram prin fiecare batch din dataloader\n",
        "    for images, labels in train_loader:\n",
        "      # Aplicam reteaua neurala pe imaginile din batch-ul curent\n",
        "      out = net(images)\n",
        "      # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor\n",
        "      loss = loss_fn(out, labels)\n",
        "      # Aplicam algoritmul de back-propagation\n",
        "      loss.backward()\n",
        "      # Facem pasul de optimizare, pentru a actualiza parametrii retelei\n",
        "      optimizer.step()\n",
        "      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n",
        "\n",
        "    # Calculam acuratetea\n",
        "    acc = test_acc(net, test_loader)\n",
        "    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e + 1, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWvb00A-TkJq"
      },
      "source": [
        "\n",
        "## Antrenarea\n",
        "\n",
        "### Cerinte\n",
        "  * Antrenati reteaua definita mai sus (clasa Net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqUwOWmDMpqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3aa989-b2af-4866-cad0-8ac5419d314b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss-ul la finalul epocii 0 are valoarea 2.3000550270080566\n",
            "Acuratetea la finalul epocii 1 este 10.31%\n",
            "Loss-ul la finalul epocii 1 are valoarea 2.3058903217315674\n",
            "Acuratetea la finalul epocii 2 este 10.40%\n",
            "Loss-ul la finalul epocii 2 are valoarea 2.2991576194763184\n",
            "Acuratetea la finalul epocii 3 este 10.52%\n",
            "Loss-ul la finalul epocii 3 are valoarea 2.300849199295044\n",
            "Acuratetea la finalul epocii 4 este 10.72%\n",
            "Loss-ul la finalul epocii 4 are valoarea 2.301738739013672\n",
            "Acuratetea la finalul epocii 5 este 10.96%\n",
            "Loss-ul la finalul epocii 5 are valoarea 2.297344207763672\n",
            "Acuratetea la finalul epocii 6 este 11.14%\n",
            "Loss-ul la finalul epocii 6 are valoarea 2.310138463973999\n",
            "Acuratetea la finalul epocii 7 este 11.56%\n",
            "Loss-ul la finalul epocii 7 are valoarea 2.2950406074523926\n",
            "Acuratetea la finalul epocii 8 este 11.78%\n",
            "Loss-ul la finalul epocii 8 are valoarea 2.2969181537628174\n",
            "Acuratetea la finalul epocii 9 este 12.14%\n",
            "Loss-ul la finalul epocii 9 are valoarea 2.2982003688812256\n",
            "Acuratetea la finalul epocii 10 este 12.47%\n"
          ]
        }
      ],
      "source": [
        "train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmVavwztTZkz"
      },
      "source": [
        "## Reteaua LeNet\n",
        "\n",
        "### Cerinte\n",
        "  * **(3p)** Implementati reteaua LeNet dupa figura de mai jos si antrenati-o.\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1OVancUyIViMRMZdULFSVCvXJHQP0NGUV)\n",
        "\n",
        "Figura arhitectura LeNet\n",
        "\n",
        "![alt text](https://debuggercafe.com/wp-content/uploads/2019/07/Layers-in-LeNet.png)\n",
        "\n",
        "Tabel arhitectura LeNet\n",
        "\n",
        "_Question:_ Care este diferenta dintre `tanh` si `softmax`? De ce credeti ca peste ultimul layer (cel de output) a fost aplicata functia `softmax`?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zoe1vbggO-4U"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \"\"\"\n",
        "    Punctaj: 2.5p\n",
        "    \"\"\"\n",
        "    ### Completati codul pentru cerinta aici\n",
        "    # Convolutii\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5), stride=(1,1), padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5), stride=(1,1), padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5,5), stride=(1,1), padding=0)\n",
        "\n",
        "    # Activare\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "    # Pooling\n",
        "    self.pooling = nn.AvgPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "\n",
        "    # Full connection\n",
        "    self.linear1 = nn.Linear(120, 84)\n",
        "    self.linear2 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "    Punctaj: 0.5p\n",
        "    \"\"\"\n",
        "    ### Completati codul pentru cerinta aici\n",
        "    x = self.tanh(self.conv1(x))\n",
        "    x = self.tanh(self.pooling(x))\n",
        "    x = self.tanh(self.conv2(x))\n",
        "    x = self.tanh(self.pooling(x))\n",
        "    x = self.tanh(self.conv3(x))\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.tanh(self.linear1(x))\n",
        "    x = self.softmax(self.linear2(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "def collate_fn(examples):\n",
        "  ### Completati codul pentru cerinta aici\n",
        "  toGreyscale = transforms.Grayscale()\n",
        "  processed_images = []\n",
        "  processed_labels = []\n",
        "\n",
        "  for example in examples: # example este un tuplu returnat de obiectul de tip Dataset\n",
        "    pil_image = example[0]\n",
        "    pil_image = toGreyscale(pil_image)\n",
        "    tensor_image = to_tensor(pil_image)\n",
        "\n",
        "    tensor_image = normalize(tensor_image, [0.5], [0.5])\n",
        "    # tensor_image = tensor_image.unsqueeze(0) # Adauga inca o dimensiune la inceputul imaginii -> 1 x 32 x 32 x 3\n",
        "    processed_images.append(tensor_image)\n",
        "\n",
        "    label = example[1]\n",
        "\n",
        "    processed_labels.append(label)\n",
        "\n",
        "  torch_images = torch.stack(processed_images)\n",
        "  torch_labels = torch.tensor(processed_labels)\n",
        "\n",
        "\n",
        "  return torch_images, torch_labels\n",
        "\n",
        "\n",
        "train_loader2 = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "test_loader2 = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "hPAyRJnT5sRE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "network = LeNet()\n",
        "\n",
        "optimizer = optim.SGD(network.parameters(), lr=1e-2)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_fn(epochs, train_loader2, test_loader2, network, loss_fn, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJgpfZ5bKQAv",
        "outputId": "0f0deb8a-588e-4afc-bd0b-edad0df12ecc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss-ul la finalul epocii 0 are valoarea 2.302501916885376\n",
            "Acuratetea la finalul epocii 1 este 9.61%\n",
            "Loss-ul la finalul epocii 1 are valoarea 2.302297353744507\n",
            "Acuratetea la finalul epocii 2 este 9.87%\n",
            "Loss-ul la finalul epocii 2 are valoarea 2.3021299839019775\n",
            "Acuratetea la finalul epocii 3 este 10.21%\n",
            "Loss-ul la finalul epocii 3 are valoarea 2.3020200729370117\n",
            "Acuratetea la finalul epocii 4 este 10.52%\n",
            "Loss-ul la finalul epocii 4 are valoarea 2.3020670413970947\n",
            "Acuratetea la finalul epocii 5 este 10.88%\n",
            "Loss-ul la finalul epocii 5 are valoarea 2.3028974533081055\n",
            "Acuratetea la finalul epocii 6 este 11.21%\n",
            "Loss-ul la finalul epocii 6 are valoarea 2.301891565322876\n",
            "Acuratetea la finalul epocii 7 este 11.42%\n",
            "Loss-ul la finalul epocii 7 are valoarea 2.3023312091827393\n",
            "Acuratetea la finalul epocii 8 este 11.59%\n",
            "Loss-ul la finalul epocii 8 are valoarea 2.3018012046813965\n",
            "Acuratetea la finalul epocii 9 este 11.76%\n",
            "Loss-ul la finalul epocii 9 are valoarea 2.3019890785217285\n",
            "Acuratetea la finalul epocii 10 este 11.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMaWPS1gXslS"
      },
      "source": [
        "## Optional: Reteaua AlexNet ❤️\n",
        "\n",
        "❗Daca alegeti aceasta retea veti continua sa rezolvati exercitiile urmatoare pentru reteaua AlexNet.\n",
        "\n",
        "Pentru a usura volumul de munca si obtine o retea AlexNet comparabila in dificultate cu LeNet, urmati acesti pasi:\n",
        "\n",
        "✔️ Includeti functii de activare intre layere (exemplu ReLU).\n",
        "\n",
        "✔️ Va folositi doar de prima subsectiune din schema figurii arhitecturii AlexNet (adica doar Conv1 si Conv2 blocks).\n",
        "\n",
        "✔️ Inputul vostru se opreste la un minimum size de 8x8.\n",
        "\n",
        "✔️ Modificati output-ul retelei sa prezica 10 clase in loc de 1000 de clase.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://anhreynolds.com/img/alexnet.png)\n",
        "\n",
        "Figura arhitectura AlexNet.\n",
        "\n",
        "![alt text](https://anhreynolds.com/img/alexnet-parameters.png)\n",
        "\n",
        "Tabel arhitectura AlexNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irXGsufhCiuG"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \"\"\"\n",
        "    Punctaj: 2.5p\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "  def forward(self,x):\n",
        "    \"\"\"\n",
        "    Punctaj: 0.5p\n",
        "    \"\"\"\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0XPmGrEol9M"
      },
      "source": [
        "## Redefinirea obiectelor folosite in timpul antrenarii pentru reteaua LeNet\n",
        "\n",
        "### Cerinta\n",
        " * Redefiniti obiectele pentru a antrena reteaua LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhqNoDmQo66c"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definiti numarul de epoci\n",
        "epochs = None\n",
        "\n",
        "# Definiti reteaua\n",
        "lenet = None\n",
        "\n",
        "# Definiti optimizatorul\n",
        "lenet_optimizer = None\n",
        "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
        "# Aceasta face toti gradientii zero.\n",
        "# Completati codul pentru a face gradientii zero aici\n",
        "\n",
        "\n",
        "# Definiti functia cost pentru clasificare Cross-Entropy\n",
        "loss_fn = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwIQwUQpo_eR"
      },
      "source": [
        "## Antrenarea retelei LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUl8W42do_sL"
      },
      "outputs": [],
      "source": [
        "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OspDtfFnTodr"
      },
      "source": [
        "###Augmentare retea\n",
        "\n",
        "Reteaua de mai devreme duce lipsa de regularizare. O forma foarte puternica de regularizare este normalizarea, iar pentru acest lucru exista straturi speciale.\n",
        "\n",
        "Astfel de straturi:\n",
        "\n",
        "* [torch.nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) (num_features)\n",
        "* [torch.nn.InstanceNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html) (num_features)\n",
        "\n",
        "Un alt element important il reprezinta functiile de activare, care pot influenta convergenta si puterea retelei. Cateva exemple de alte functii de activare:\n",
        "\n",
        "* ReLU\n",
        "* Sigmoid\n",
        "* Tanh\n",
        "* LeakyRelu\n",
        "* GELU\n",
        "\n",
        "## Cerinta\n",
        "\n",
        "**(2p)** Experimentati cu aceste elemente in cadrul retelei LeNet definita mai devreme, pentru a obtine o acuratete mai buna. Observati viteza de convergenta si performanta retelei pentru 3 configuratii diferite.\n",
        "\n",
        "**Punctaj:** 0.6p / configuratie.\n",
        "\n",
        "0.6p din care:\n",
        "- 0.4p modificarea retelei\n",
        "- 0.1p obtinerea rezultatelor\n",
        "- 0.1p afisarea acestora si explicatie.\n",
        "\n",
        "\n",
        "###Bonus\n",
        "**(1p)** Antrenati reteaua folosind GPU (Graphics processing unit)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bROgHAlKYRv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}