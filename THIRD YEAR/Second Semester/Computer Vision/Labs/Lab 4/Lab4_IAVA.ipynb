{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Laborator 4\n","\n","In cadrul acestui laborator o sa lucram cu blocurile de baza necesare construirii unor retele mai complexe. De interes sunt:\n","\n","\n","*   Residual Blocks\n","*   Inception Blocks\n","\n","Pe langa acestea, o sa aplicam si augmentari generale de date care au rolul de a face modelul robust la variatii mici.\n","\n"],"metadata":{"id":"lDW1eb9Q-oZt"}},{"cell_type":"markdown","source":["## Operatii Noi\n","\n","Urmatoarele operatii vor fi folosite in cadrul laboratorului\n","\n","Tensor shape: (batch,channels,dim1,dim2)\n","\n","\n","*  **torch.cat(tensors, dim=0).** Tensorii trebuie sa aiba aceleasi dim1,dim2, dar channels poate sa difere.\n","*  **torch.add(input, other)**. Tensorii trebuie sa aiba aceleasi dimensiune pe toate axele.\n","\n","\n","\n"],"metadata":{"id":"IQM3j32e-sFW"}},{"cell_type":"code","source":["import numpy as np\n","import torch.nn as nn\n","import torch\n","\n","dummy_input_tensor1 = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","dummy_input_tensor2 = torch.rand((1,5,100,100))  # Input random de marime 100x100 cu 5 canale\n","\n","# Normal se concateneaza pe dimensiunea canalelor.\n","x = torch.cat([dummy_input_tensor1,dummy_input_tensor2],dim=1)\n","print(x.shape) # Numarul de canele_output = canale_input2 + canale_input1\n","\n","dummy_input_tensor1 = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","dummy_input_tensor2 = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","\n","x = torch.add(dummy_input_tensor1,dummy_input_tensor2)\n","print(x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaWNdZ7q-v7C","outputId":"c556790a-7f06-4398-d9dd-ebf7c2b682ee","executionInfo":{"status":"ok","timestamp":1712767220506,"user_tz":-180,"elapsed":402,"user":{"displayName":"Radu Nedelcu","userId":"06705643835593513111"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 8, 100, 100])\n","torch.Size([1, 3, 100, 100])\n"]}]},{"cell_type":"markdown","source":["##Residual Block\n","\n","In cadrul Resnet se utilizeaza residual connections / skip connections, care impreuna cu un path normal, ca cele implementate pana acum, formeaza un residual block.\n","\n","<img src=\"https://user-images.githubusercontent.com/6086781/28494249-97e81166-6ef6-11e7-88b8-fa4aa184bc0b.png\" alt=\"Drawing\" style=\"height: 400px;\"/>\n","\n","\n","###Cerinta 1 - **(3p)**\n","\n","Implementati ResidualBlock. Acesta duce input tensor din ($c_{input}$,width,height) in  ($c_{out}$,width,height) sau  ($c_{out}$,width/2,height/2) in functie de stride. (Puteti implemnta oricare dintre variantele din imagine)\n","\n","\n"],"metadata":{"id":"QPM-6I-t-1OR"}},{"cell_type":"code","source":["import numpy as np\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","\n","class ResidualBlock(nn.Module):\n","  def __init__(self,input_channels=32,hidden_channels=64,output_channels=64,kernel_size=3,stride=1,activation=nn.ReLU()):\n","    super(ResidualBlock,self).__init__()\n","    layers = [\n","            nn.Conv2d(input_channels, hidden_channels, kernel_size, stride=stride, padding=1),\n","            nn.BatchNorm2d(hidden_channels),\n","            activation,\n","            nn.Conv2d(hidden_channels, output_channels, kernel_size, stride=1, padding=1),\n","            nn.BatchNorm2d(output_channels)\n","    ]\n","\n","\n","    self.net_normal = nn.Sequential(*layers)\n","\n","    self.net_residual = nn.Conv2d(input_channels,output_channels,1,stride)\n","\n","  def forward(self,x):\n","    x = torch.add(self.net_normal(x),self.net_residual(x))\n","    x = F.relu(x)\n","    return x\n","\n","# block = ResidualBlock(3,64,128,3,1,nn.ReLU())\n","# x = torch.rand(size=(1,3,100,100))\n","\n","# stride=2 halves size output size\n","block = ResidualBlock(3,64,128,3,2,nn.ReLU())\n","x = torch.rand(size=(1,3,100,100))\n","\n","# Should output torch.Size([1, 128, 50, 50])\n","print(block(x).shape)"],"metadata":{"id":"Qt3Oz3lHE5sW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712767221327,"user_tz":-180,"elapsed":462,"user":{"displayName":"Radu Nedelcu","userId":"06705643835593513111"}},"outputId":"cbfffe22-e1ea-4f40-b644-ab1017bf8010"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 128, 50, 50])\n"]}]},{"cell_type":"markdown","source":["##Inception Block\n","\n","In cadrul GoogleNet/InceptionNet este folosit Inception Block, care este alcatuit din mai multe mini-retele putin diferite, care se unesc la finalul Inception Block\n","\n","### Cerinta 2 - **(3p)**\n","\n","Implementati Inception Block. Acesta trebuie sa duca un Tensor ($ch_{input}$,w,h) in ($ch_{out}$,w/2,h/2)\n","\n","Punctaj:\n","- cate **0.5p** pentru fiecare path implementat corect **(4 * 0.5p = 2p)**\n","- codul ruleaza si rezultatul final este corect (**1p**)\n","\n","\n","<!-- ![InceptionBlock](https://drive.google.com/uc?export=view&id=11eiInGoQoytm_N0989v5oJnKpFrspUzk) -->\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=11eiInGoQoytm_N0989v5oJnKpFrspUzk\" alt=\"Drawing\" style=\"height: 200px; width:200px;\"/>"],"metadata":{"id":"19qJYsJKE9ub"}},{"cell_type":"code","source":["import numpy as np\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","\n","\n","class InceptionBlock(nn.Module):\n","  def __init__(self,input_channels=32,kernel_size=3,stride=1,activation=nn.ReLU()):\n","    super(InceptionBlock,self).__init__()\n","\n","    output_size = 64\n","\n","    layers = [\n","        nn.Conv2d(input_channels, 64, kernel_size=1, stride=stride),\n","        nn.BatchNorm2d(64),\n","        activation,\n","        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(128),\n","        activation,\n","        nn.Conv2d(128, output_size, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(output_size),\n","        activation\n","    ]\n","\n","    self.path1 = nn.Sequential(*layers)\n","\n","    layers = [\n","        nn.Conv2d(input_channels, 128, kernel_size=1, stride=stride),\n","        nn.BatchNorm2d(128),\n","        activation,\n","        nn.Conv2d(128, output_size, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(output_size),\n","        activation\n","    ]\n","\n","    self.path2 = nn.Sequential(*layers)\n","\n","    layers = [\n","        nn.MaxPool2d(kernel_size, stride=stride, padding=1),\n","        nn.Conv2d(input_channels, output_size, kernel_size=1),\n","        nn.BatchNorm2d(output_size),\n","        activation\n","    ]\n","\n","    self.path3 = nn.Sequential(*layers)\n","\n","    layers = [\n","        nn.Conv2d(input_channels, output_size, kernel_size=1, stride=stride),\n","        nn.BatchNorm2d(output_size),\n","        activation\n","    ]\n","\n","    self.path4 = nn.Sequential(*layers)\n","\n","  def forward(self,x):\n","    x1 = self.path1(x)\n","    # print(x1.shape)\n","    x2 =self.path2(x)\n","    # print(x2.shape)\n","    x3 =self.path3(x)\n","    # print(x3.shape)\n","    x4 =self.path4(x)\n","    # print(x4.shape)\n","    x = torch.cat([x1,x2,x3,x4],1)\n","    return x\n","\n","block = InceptionBlock(64,3,2,nn.ReLU())\n","x = torch.rand(size=(1,64,100,100))\n","\n","# Should output torch.Size([1, 256, 50, 50])\n","print(block(x).shape)"],"metadata":{"id":"yuLzccpCFCdq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712767221834,"user_tz":-180,"elapsed":508,"user":{"displayName":"Radu Nedelcu","userId":"06705643835593513111"}},"outputId":"4e786b16-3312-4924-ce53-5d2368c72312"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 256, 50, 50])\n"]}]},{"cell_type":"markdown","source":["## Instantierea seturilor de date\n","\n","In acest laborator lucram cu un nou set de date. Este vorba de un dataset folosit in [aceasta competitie Kaggle](https://www.kaggle.com/c/dogs-vs-cats/overview), Pisici vs Caini.\n","\n","***In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.***\n"],"metadata":{"id":"R0k1tO2ZFGpg"}},{"cell_type":"markdown","source":["# Descarcarea setului de date\n","\n","### Authenticating with Kaggle using kaggle.json\n","\n","Navigate to https://www.kaggle.com. Then go to the [Account tab of your user profile](https://www.kaggle.com/me/account) and select Create API Token. This will trigger the download of kaggle.json, a file containing your API credentials.\n","\n","Then run the cell below to upload kaggle.json to your Colab runtime.\n"],"metadata":{"id":"4q25m42UFJr5"}},{"cell_type":"code","source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","# Then move kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"QvH0ztGpFPKP","colab":{"base_uri":"https://localhost:8080/","height":38},"outputId":"cffea8d5-7d68-4a1f-f0cc-875be3085cc6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8e445439-5659-4f2e-b6d7-b8faec277256\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8e445439-5659-4f2e-b6d7-b8faec277256\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"q5q2aFDIDYFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1AiFVPoEDY5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install kaggle\n","!kaggle competitions download -c dogs-vs-cats\n","!for z in *.zip; do unzip \"$z\"; done\n","!ls"],"metadata":{"id":"ifUxqQDTFUK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip train.zip\n","!unzip test1.zip"],"metadata":{"id":"d6tk4L0eC_EV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Crearea Dataloader-ului\n","\n","In continuare, pentru a incarca date, sa o folosim un obiect mai complex, un Torch.utils.data.Dataset. Acesta are 3 functii importante:\n","\n","\n","*   __init__()\n","*   ____len____()\n","*  ____get_item____()\n","\n"],"metadata":{"id":"kYGkB4LMFWeJ"}},{"cell_type":"code","source":["import torch as t\n","from PIL import Image\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms.functional import to_tensor, normalize\n","import random, os\n","random.seed(42)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","train_dir = '../data/train'\n","test_dir = '../data/test'\n","\n","class CatsDogsDataset(Dataset):\n","    def __init__(self, file_list, width=128, height=128, transform=None):\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.img_size = (width, height)\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self,idx):\n","        img_path = self.file_list[idx]\n","        img = Image.open(img_path)\n","\n","        original_width, original_height = img.size\n","\n","        img = img.resize(self.img_size)\n","        img = np.array(img)\n","\n","        label = img_path.split('/')[-1].split('.')[0]\n","        if label == 'dog':\n","            label = 1\n","        elif label == 'cat':\n","            label = 0\n","\n","        return to_tensor(img), label"],"metadata":{"id":"EiGg7Q0TFZ5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bNClbReapKhj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Construire Dataset si vizualizare date."],"metadata":{"id":"yLkN9ahaFdNS"}},{"cell_type":"code","source":[],"metadata":{"id":"yG2re81PYtu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import clear_output\n","import time\n","\n","train_test_proportion = .85\n","\n","import glob\n","\n","samples = glob.glob(os.path.join('./train','*.jpg'))\n","random.shuffle(samples)\n","\n","train_samples = samples[:int(train_test_proportion*len(samples))]\n","test_samples = samples[int(train_test_proportion*len(samples)):]\n","\n","cats_dogs_train = CatsDogsDataset(train_samples,128,128)\n","cats_dogs_test = CatsDogsDataset(test_samples,128,128)\n","\n","train_loader = DataLoader(cats_dogs_train, batch_size=16, shuffle=True, num_workers=4)\n","test_loader = DataLoader(cats_dogs_test, batch_size=16, shuffle=False, num_workers=4)\n","\n","see_examples = 10\n","for i, (imgs, label) in enumerate(train_loader):\n","    clear_output(wait=True)\n","    image = imgs[0].numpy().transpose(1, 2, 0)\n","    plt.imshow(image)\n","    plt.text(5, 30, \"DOG\" if label[0] else \"CAT\", fontsize ='xx-large', color='red', fontweight='bold')\n","    plt.show()\n","\n","    if i >= see_examples - 1:\n","      break\n","    time.sleep(1)\n"],"metadata":{"id":"pTlS3MgDFfze"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cerinta 3 - **(4p)**\n","\n","  1. Antrenati o retea convolutionala (o arhitectura la alegere din laboratorul 3) folosind acest dataset, pe GPU (https://pytorch.org/docs/stable/notes/cuda.html) **(1p)**\n","  2. Antrenati o retea de tip Resnet (folosind blocuri de tip Residual) **(1p)**\n","  3. Antrenati o retea de tip Inception (folosind blocuri de tip Inception)  **(1p)**\n","  4. Experimentati cu diferiti hyperparameters (numarul de layers, numarul de filtre/neuroni, etc.) **(1p)**\n"],"metadata":{"id":"tzBTPXxmFiND"}},{"cell_type":"code","source":["import torch as t\n","from PIL import Image\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms.functional import to_tensor, normalize\n","import random, os\n","random.seed(37)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","train_dir = '../data/train'\n","test_dir = '../data/test'\n","\n","class CatsDogsDataset(Dataset):\n","    def __init__(self, file_list, width=128, height=128, transform=None):\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.img_size = (width, height)\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self,idx):\n","        img_path = self.file_list[idx]\n","        img = Image.open(img_path)\n","\n","        original_width, original_height = img.size\n","\n","        img = img.resize(self.img_size)\n","        img = np.array(img)\n","\n","        label = img_path.split('/')[-1].split('.')[0]\n","        if label == 'dog':\n","            label = 1\n","        elif label == 'cat':\n","            label = 0\n","\n","        return to_tensor(img), label\n","\n","\n","from IPython.display import clear_output\n","import time\n","\n","train_test_proportion = .85\n","\n","import glob\n","\n","samples = glob.glob(os.path.join('./train','*.jpg'))\n","random.shuffle(samples)\n","\n","train_samples = samples[:int(train_test_proportion*len(samples))]\n","test_samples = samples[int(train_test_proportion*len(samples)):]\n","\n","cats_dogs_train = CatsDogsDataset(train_samples,32,32)\n","cats_dogs_test = CatsDogsDataset(test_samples,32,32)\n","\n","train_loader = DataLoader(cats_dogs_train, batch_size=16, shuffle=True, num_workers=4)\n","test_loader = DataLoader(cats_dogs_test, batch_size=16, shuffle=False, num_workers=4)\n"],"metadata":{"id":"76M-DQkNzvwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchvision.transforms.functional import to_tensor, normalize\n","import torchvision.transforms as transforms\n","\n","device = torch.device(\"cuda\")\n","\n","class LeNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    # Convolutii\n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5), stride=(1,1), padding=0)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5), stride=(1,1), padding=0)\n","    self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(5,5), stride=(2,2), padding=0)\n","\n","    # Activare\n","    self.tanh = nn.Tanh()\n","    self.softmax = nn.Softmax()\n","\n","    # Pooling\n","    self.pooling = nn.AvgPool2d(kernel_size=(2,2), stride=(2,2))\n","\n","    # Full connection\n","    self.linear1 = nn.Linear(16, 84)\n","    self.linear2 = nn.Linear(84, 2)\n","\n","  def forward(self,x):\n","\n","    x = self.tanh(self.conv1(x))\n","    x = self.tanh(self.pooling(x))\n","    x = self.tanh(self.conv2(x))\n","    x = self.tanh(self.pooling(x))\n","    x = self.tanh(self.conv3(x))\n","\n","    x = x.view(x.size(0), -1)\n","    x = self.tanh(self.linear1(x))\n","    x = self.softmax(self.linear2(x))\n","    return x\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"yuN0Soi2fq4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_acc(net: nn.Module, test_loader: DataLoader):\n","  net.eval()\n","\n","  total = 0\n","  correct = 0\n","\n","  for test_images, test_labels in test_loader:\n","    test_images, test_labels = test_images.to(device), test_labels.to(device)\n","    total += len(test_images)\n","    out_class = torch.argmax(net(test_images))\n","    correct += torch.sum(out_class == test_labels)\n","\n","  return correct / total * 100\n","\n","\n","def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader,\n","             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n","  # Iteram prin numarul de epoci\n","  for e in range(epochs):\n","    net.train()\n","\n","    # Iteram prin fiecare batch din dataloader\n","    for images, labels in train_loader:\n","      # Trecerea pe cuda\n","      images, labels = images.to(device), labels.to(device)\n","      # Aplicam reteaua neurala pe imaginile din batch-ul curent\n","      out = net(images)\n","      # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor\n","      loss = loss_fn(out, labels)\n","      # Aplicam algoritmul de back-propagation\n","      loss.backward()\n","      # Facem pasul de optimizare, pentru a actualiza parametrii retelei\n","      optimizer.step()\n","      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n","      optimizer.zero_grad()\n","\n","    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n","\n","    # Calculam acuratetea\n","    acc = test_acc(net, test_loader)\n","    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e + 1, acc))"],"metadata":{"id":"ihnAXlbWhBkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","\n","network = LeNet().to(device)\n","\n","optimizer = optim.SGD(network.parameters(), lr=1e-2)\n","optimizer.zero_grad()\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"],"metadata":{"id":"b_2JM-TxhB67"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchvision.transforms.functional import to_tensor, normalize\n","import torchvision.transforms as transforms\n","\n","class LeNet2(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    # Convolutii\n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5), stride=(1,1), padding=0)\n","    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5), stride=(1,1), padding=0)\n","    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5,5), stride=(2,2), padding=0)\n","    self.conv4 = nn.Conv2d(in_channels=120, out_channels=64, kernel_size=(5,5), stride=(1,1), padding=0)\n","\n","    # Activare\n","    self.relu = nn.ReLU()\n","    self.softmax = nn.Softmax()\n","\n","    # Pooling\n","    self.pooling = nn.AvgPool2d(kernel_size=(2,2), stride=(2,2))\n","\n","    # Full connection\n","    self.linear1 = nn.Linear(64, 32)\n","    self.linear2 = nn.Linear(32, 2)\n","\n","  def forward(self,x):\n","\n","    x = self.relu(self.conv1(x))\n","    x = self.relu(self.pooling(x))\n","    x = self.relu(self.conv2(x))\n","    x = self.relu(self.pooling(x))\n","    x = self.relu(self.conv3(x))\n","    x = self.relu(self.pooling(x))\n","    x = self.relu(self.conv4(x))\n","\n","    x = x.view(x.size(0), -1)\n","    x = self.softmax(self.linear1(x))\n","    x = self.softmax(self.linear2(x))\n","    return x\n"],"metadata":{"id":"JMJ5smY8pMLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","epochs = 15\n","\n","network = LeNet().to(device)\n","\n","optimizer = optim.SGD(network.parameters(), lr=(1e-3)*2)\n","optimizer.zero_grad()\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"],"metadata":{"id":"vVhvleK5ygvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"7gC7qggg0qWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchvision.transforms.functional import to_tensor, normalize\n","import torchvision.transforms as transforms\n","\n","\n","\n","def test_acc(net: nn.Module, test_loader: DataLoader):\n","  net.eval()\n","\n","  total = 0\n","  correct = 0\n","\n","  for test_images, test_labels in test_loader:\n","    test_images, test_labels = test_images, test_labels\n","    total += len(test_images)\n","    out_class = torch.argmax(net(test_images))\n","    correct += torch.sum(out_class == test_labels)\n","\n","  return correct / total * 100\n","\n","\n","def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader,\n","             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n","  # Iteram prin numarul de epoci\n","  for e in range(epochs):\n","    net.train()\n","\n","    # Iteram prin fiecare batch din dataloader\n","    for images, labels in train_loader:\n","      # Trecerea pe cuda\n","      images, labels = images, labels\n","      # Aplicam reteaua neurala pe imaginile din batch-ul curent\n","      out = net(images)\n","      # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor\n","      loss = loss_fn(out, labels)\n","      # Aplicam algoritmul de back-propagation\n","      loss.backward()\n","      # Facem pasul de optimizare, pentru a actualiza parametrii retelei\n","      optimizer.step()\n","      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n","      optimizer.zero_grad()\n","\n","    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n","\n","    # Calculam acuratetea\n","    acc = test_acc(net, test_loader)\n","    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e + 1, acc))\n","\n","class LeNetWithInception(nn.Module):\n","    def __init__(self):\n","        super(LeNetWithInception, self).__init__()\n","\n","        # First Inception Block\n","        self.inception1 = InceptionBlock(input_channels=3, kernel_size=3, stride=2, activation=nn.ReLU())\n","\n","        # Convolutional layers\n","\n","        self.conv1 = nn.Conv2d(in_channels=256, out_channels=120, kernel_size=(5,5), stride=(1,1), padding=0)\n","        self.conv2 = nn.Conv2d(in_channels=120, out_channels=16, kernel_size=(5,5), stride=(1,1), padding=0)\n","\n","\n","        # Activation function\n","        self.relu = nn.ReLU()\n","\n","\n","\n","        # Full connection\n","        self.linear1 = nn.Linear(1024, 16)\n","        self.linear2 = nn.Linear(16, 2)\n","\n","    def forward(self, x):\n","        x = self.inception1(x)\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.linear1(x))\n","        # x = self.relu(self.linear2(x)) -> fara\n","        # Daca folosim nn.CrossEntropyLoss(), nu mai este nevoie de functie de activare pe ultimul nivel\n","        x = self.linear2(x)\n","        return x\n","\n","# Initialize the model\n","\n","# device = torch.device(\"cuda\")\n","# network = LeNetWithInception().to(device)\n","network = LeNetWithInception()\n","\n","# Define the optimizer and loss function\n","optimizer = optim.SGD(network.parameters(), lr=0.001)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Train the model\n","epochs = 5\n","train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"],"metadata":{"id":"U7D5JngT0vNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_acc(net: nn.Module, test_loader: DataLoader):\n","  net.eval()\n","\n","  total = 0\n","  correct = 0\n","\n","  for test_images, test_labels in test_loader:\n","    test_images, test_labels = test_images, test_labels\n","    total += len(test_images)\n","    out_class = torch.argmax(net(test_images))\n","    correct += torch.sum(out_class == test_labels)\n","\n","  return correct / total * 100\n","\n","\n","def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader,\n","             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n","  # Iteram prin numarul de epoci\n","  for e in range(epochs):\n","    net.train()\n","\n","    # Iteram prin fiecare batch din dataloader\n","    for images, labels in train_loader:\n","      # Trecerea pe cuda\n","      images, labels = images, labels\n","      # Aplicam reteaua neurala pe imaginile din batch-ul curent\n","      out = net(images)\n","      # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor\n","      loss = loss_fn(out, labels)\n","      # Aplicam algoritmul de back-propagation\n","      loss.backward()\n","      # Facem pasul de optimizare, pentru a actualiza parametrii retelei\n","      optimizer.step()\n","      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n","      optimizer.zero_grad()\n","\n","    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n","\n","    # Calculam acuratetea\n","    acc = test_acc(net, test_loader)\n","    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e + 1, acc))\n","\n","class LeNetWithResidual(nn.Module):\n","    def __init__(self):\n","        super(LeNetWithResidual, self).__init__()\n","\n","        self.residual = ResidualBlock(input_channels=3, kernel_size=3, stride=2, activation=nn.ReLU())\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(in_channels=64, out_channels=120, kernel_size=(5,5), stride=(1,1), padding=0)\n","        self.conv2 = nn.Conv2d(in_channels=120, out_channels=8, kernel_size=(5,5), stride=(1,1), padding=0)\n","\n","        # Activation function\n","        self.relu = nn.ReLU()\n","\n","        # Full connection\n","        self.linear1 = nn.Linear(512, 1024)\n","        self.linear2 = nn.Linear(1024, 2)\n","\n","    def forward(self, x):\n","        x = self.residual(x)\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.relu(self.conv2(x))\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.linear1(x))\n","        x = self.linear2(x)\n","\n","# Initialize the model\n","\n","# device = torch.device(\"cuda\")\n","# network = LeNetWithInception().to(device)\n","network = LeNetWithInception()\n","\n","# Define the optimizer and loss function\n","optimizer = optim.SGD(network.parameters(), lr=0.001)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Train the model\n","epochs = 5\n","train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"],"metadata":{"id":"51R6q3YsLh7A"},"execution_count":null,"outputs":[]}]}